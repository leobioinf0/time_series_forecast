{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DUMMY_NUMBERS.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "lwK_LhjXqb_i",
        "C6TpHfdVs3Zw",
        "wkQUHxuTgfWd",
        "mO_n-WmCtdD8",
        "5sGeAR_nfEvt",
        "WBeCXSUUqsc1",
        "p4dMD4ApprJd",
        "ThTVdLdXRoJY",
        "W0mhM05qu38S",
        "Q6nkFS8dQmix",
        "28cnaeLE9Js1",
        "5CWPj4axF798",
        "sHO3_X27Ukbk",
        "H76DQjrBleOf",
        "qCqUk_ACGCa0",
        "Jomf6tCjTKZf",
        "-XW_dgMdHGXG",
        "MSS6_LaW1qh_",
        "BLHqN-SCptQV",
        "Kx1cJWdNQmjG",
        "czOiMggZ7nUh",
        "j-1X_VPcIVZQ",
        "U58jyFoUNc71",
        "DdklEkWm4ZZQ",
        "8SONOLw1NdAq",
        "Upz-o4S2Ho76",
        "47qEXJ7FCc5k",
        "I0rptD8yp7QM",
        "FpznGBhXG5pq",
        "9LB8Uy4UMFqp",
        "EtLoH3lMGXiD",
        "rrfFkFfD8T9W",
        "VAQX9LDcFjQc",
        "iEr60E_E07eo",
        "bfhu_rLo8T9s",
        "wjEcRuw-2mSZ",
        "sZooX0vb2K-J",
        "z0m5KocVqPS4",
        "69kucKT7-0D5",
        "gJ7VRNkH-0D7",
        "0EUrXlGj4M1h",
        "0RB5VBTxGTdg",
        "pEFH8gmXqM4I",
        "81FkRlhNfILR",
        "ynDMBq4ODM8z",
        "hWEKEQ6-wJNn",
        "4ETQJfNoi-I3",
        "3Zu6asq6bqNG",
        "Jjv8pXPSbufi",
        "rGUsELw4Hmnb",
        "oamFPFSyjEej"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pqc_IbLqRXJ"
      },
      "source": [
        "He utilizado el dataset \"DEALS_DETAIL-DUMMY_NUMBERS.csv\" para realizar un análisis exploratorios con el objetivo de obtener información valiosa y luego realizar un análisis de series la serie temporal y obtener un pronóstico de ventas de 7 días. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0455OoR3tjo"
      },
      "source": [
        "!pip3 install -U pmdarima\n",
        "!pip3 install -U tbats\n",
        "!pip3 install -U keras-tcn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-863I6ltua_"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwK_LhjXqb_i"
      },
      "source": [
        "# Librerias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DevPXKvUB43T"
      },
      "source": [
        "import gc\n",
        "import sys\n",
        "import glob\n",
        "import re\n",
        "import os\n",
        "import pickle\n",
        "import urllib\n",
        "import json\n",
        "import datetime\n",
        "import holidays\n",
        "import pprint\n",
        "import warnings\n",
        "import time\n",
        "import itertools\n",
        "from tqdm import tqdm_notebook\n",
        "from math import sqrt\n",
        "import numpy as np\n",
        "from numpy import savetxt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from collections import defaultdict\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import load_model, Sequential\n",
        "from tensorflow.keras.layers import InputLayer, Layer, Dense, LSTM, GRU, Flatten\n",
        "from tensorflow.keras.layers import Conv1D, MaxPool1D, Dropout, Activation, Masking\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow import keras\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.tsa.stattools import adfuller, kpss, ARMA\n",
        "from statsmodels.tsa.arima_model import ARIMA, ARIMAResults\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX, SARIMAXResults\n",
        "from statsmodels.graphics import tsaplots as sgt\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, max_error\n",
        "from sklearn.metrics import r2_score, explained_variance_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from tcn import TCN\n",
        "from pmdarima import auto_arima\n",
        "from tbats import BATS, TBATS\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use('fast')\n",
        "plt.rcParams[\"figure.figsize\"] = (15, 7)\n",
        "sns.set_context(\"paper\", rc={\"lines.linewidth\": 1})\n",
        "tf.random.set_seed(1)\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "pd.set_option('max_colwidth', None)\n",
        "pd.set_option(\"display.max_rows\", 100)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "sns.set(style='whitegrid', palette='muted')\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "# Diccionarios para guardar los resultados\n",
        "res_pronos = defaultdict(lambda: {})\n",
        "res_tiempos = defaultdict(lambda: {})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Az7qDmYdtglu"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6TpHfdVs3Zw"
      },
      "source": [
        "# Funciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkQUHxuTgfWd"
      },
      "source": [
        "### Funciones Auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn7Rbct0gB1o"
      },
      "source": [
        "def plot_line(df, ttl, path):\n",
        "    plt.plot(df)\n",
        "    plt.title(ttl, fontsize=12)\n",
        "    plt.yticks(fontsize=10)\n",
        "    plt.xticks(pd.date_range(df.index.min(),\n",
        "                             df.index.max(),\n",
        "                             freq='7D'),\n",
        "               rotation='vertical',\n",
        "               size=5)\n",
        "    plt.xlabel(df.index.name, fontsize=10)\n",
        "    plt.ylabel(df.columns[0], fontsize=10)\n",
        "    plt.savefig(os.path.join(path, df.columns[0]+\"-\"+df.index.name+\".pdf\"))\n",
        "    plt.show()\n",
        "\n",
        "def fit_model(x_tr, y_tr, b_s):\n",
        "    print(\"\\n{}: Inicio entrenamiento\".format(datetime.datetime.now()))\n",
        "    history = model.fit(x_tr, y_tr, epochs=500, batch_size=b_s, verbose=1, \n",
        "                        validation_split=.3, callbacks=mis_callbacks)\n",
        "    return history\n",
        "\n",
        "def plot_pronos(data, nombre, column):\n",
        "    print(\"\\n{}: Plot pronóstico modelo:\\t{}\".format(datetime.datetime.now(), nombre))\n",
        "    prono_plot_path = os.path.join(plot_mercado_path, nombre + \"_p.png\")\n",
        "\n",
        "    '''Plot de los pronósticos'''\n",
        "    data.filter(items=[column, nombre], axis=1).plot(figsize=(15, 7))\n",
        "    plt.ylabel(column)\n",
        "    plt.xlabel('Fecha')\n",
        "    plt.title(column.replace(\"_\", \" \") +\n",
        "              \"\\nPronósticos de %i hs.\" % len(data) +\n",
        "              \"\\n Modelo %s\" % nombre.rstrip(\"-\" + column).replace(\"_\", \" \"),\n",
        "              size=24)\n",
        "    # plt.legend(bbox_to_anchor=(1.02, 1), loc=2, borderaxespad=0.)\n",
        "    plt.autoscale()\n",
        "    plt.savefig(prono_plot_path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "def forecast_nn():\n",
        "    print(\"{}: Pronosticando\".format(datetime.datetime.now()))\n",
        "    fc = model.predict(x_test, verbose=1)\n",
        "    fc = scaler.inverse_transform(fc)[0]\n",
        "    df_test[nombre_modelo] = fc\n",
        "    pronos_tabla_path = os.path.join(tabla_mercado_path, nombre_modelo + \"_p.csv\")\n",
        "    print(\"\\n{}: Guardando pronósticos en:\\t{}\".format(datetime.datetime.now(), pronos_tabla_path))\n",
        "    df_test.to_csv(pronos_tabla_path)\n",
        "    return fc\n",
        "\n",
        "def forecast(modelo):    \n",
        "    print(\"{}: Pronosticando\".format(datetime.datetime.now()))\n",
        "    fc = modelo.forecast(horizonte_prevision, alpha=0.05)[0]\n",
        "    df_test[nombre_modelo] = fc\n",
        "    pronos_tabla_path = os.path.join(tabla_mercado_path, nombre_modelo + \"_p.csv\")\n",
        "    print(\"\\n{}: Guardando pronósticos en:\\t{}\".format(datetime.datetime.now(), pronos_tabla_path))\n",
        "    df_test.to_csv(pronos_tabla_path)\n",
        "    return fc\n",
        "\n",
        "def prediction(modelo):\n",
        "    print(\"\\n{}: Pronosticando\".format(datetime.datetime.now()))\n",
        "    fc = modelo.predict(horizonte_prevision)\n",
        "    df_test[nombre_modelo] = fc\n",
        "    pronos_tabla_path = os.path.join(tabla_mercado_path, nombre_modelo + \"_p.csv\")\n",
        "    print(\"\\n{}: Guardando pronósticos en:\\t{}\".format(datetime.datetime.now(), pronos_tabla_path))\n",
        "    df_test.to_csv(pronos_tabla_path)\n",
        "    return fc\n",
        "\n",
        "def diagnostic(modelo):    \n",
        "    print(\"\\n{}: plot_diagnostics: \".format(datetime.datetime.now()))\n",
        "    diagnostics_plot_path = os.path.join(plot_mercado_path,\n",
        "                                            nombre_modelo + \"_d.png\")\n",
        "    modelo.plot_diagnostics(figsize=(15, 15))\n",
        "    plt.savefig(diagnostics_plot_path)\n",
        "    plt.show()\n",
        "\n",
        "def plot_pronos_sarima(modelo, test):\n",
        "    pred = modelo.get_prediction(start=df_test.index.min(), \n",
        "                                                    end=df_test.index.max(), \n",
        "                                                    full_results=True)\n",
        "    pred_val = pred.conf_int()\n",
        "    ax = test.plot() \n",
        "    pred.predicted_mean.plot(ax=ax, label='One-step ahead Forecast', \n",
        "                               alpha=.7, figsize=(14, 7))\n",
        "    ax.fill_between(pred_val.index,\n",
        "                    pred_val.iloc[:, 0],\n",
        "                    pred_val.iloc[:, 1], color='k', alpha=.2)\n",
        "    ax.set_xlabel('Date')\n",
        "    ax.set_ylabel(test.columns[0])\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_pie_cant(x, y):\n",
        "    total_cant_dia = y.sum()\n",
        "    total_cant_dia = str(int(total_cant_dia))\n",
        "\n",
        "    plt.rcParams['font.size'] = 10.0\n",
        "    plt.rcParams['font.weight'] = 6\n",
        "\n",
        "    def autopct_format(values):\n",
        "        def my_format(pct):\n",
        "            total = sum(values)\n",
        "            val = int(round(pct * total / 100.0))\n",
        "            return ' {v:d}'.format(v=val)\n",
        "\n",
        "        return my_format\n",
        "\n",
        "    colors = ['#BC243C', '#FE840E', '#C62168']\n",
        "    explode = explode = tuple([0.05] * len(x))\n",
        "    fig1, ax1 = plt.subplots()\n",
        "\n",
        "    ax1.pie(y,\n",
        "            colors=colors,\n",
        "            labels=x,\n",
        "            autopct=autopct_format(y),\n",
        "            startangle=90,\n",
        "            explode=explode)\n",
        "    centre_circle = plt.Circle((0, 0), 0.82, fc='white')\n",
        "    fig = plt.gcf()\n",
        "    fig.gca().add_artist(centre_circle)\n",
        "\n",
        "    ax1.axis('equal')\n",
        "\n",
        "    label = ax1.annotate('Total \\n' + str(total_cant_dia),\n",
        "                         color='red',\n",
        "                         xy=(0, 0),\n",
        "                         fontsize=10,\n",
        "                         ha=\"center\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_pie_comi(x, y):\n",
        "    total_cant_dia = y.sum()\n",
        "    total_cant_dia = str(int(total_cant_dia))\n",
        "    plt.rcParams[\"figure.figsize\"] = (13, 5)\n",
        "    plt.rcParams['font.size'] = 10\n",
        "    plt.rcParams['font.weight'] = 6\n",
        "\n",
        "    def autopct_format(values):\n",
        "        def my_format(pct):\n",
        "            total = sum(values)\n",
        "            val = int(round(pct * total / 100.0))\n",
        "            return '${v:d}'.format(v=val)\n",
        "\n",
        "        return my_format\n",
        "\n",
        "    colors = ['#BC243C', '#FE840E', '#C62168']\n",
        "    explode = explode = tuple([0.05] * len(x))\n",
        "    fig1, ax1 = plt.subplots()\n",
        "\n",
        "    ax1.pie(y,\n",
        "            colors=colors,\n",
        "            labels=x,\n",
        "            autopct=autopct_format(y),\n",
        "            startangle=90,\n",
        "            explode=explode)\n",
        "    centre_circle = plt.Circle((0, 0), 0.82, fc='white')\n",
        "    fig = plt.gcf()\n",
        "    fig.gca().add_artist(centre_circle)\n",
        "\n",
        "    ax1.axis('equal')\n",
        "\n",
        "    label = ax1.annotate('Total \\n' + '$' + str(total_cant_dia),\n",
        "                         color='red',\n",
        "                         xy=(0, 0),\n",
        "                         fontsize=10,\n",
        "                         ha=\"center\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_bar(x, y, title, xlab, ylab):\n",
        "    plt.title(title, fontsize=18)\n",
        "    plt.bar(x, y, color='#99ff99', edgecolor='green', linewidth=1)\n",
        "    plt.xlabel(xlab, fontsize=15)\n",
        "    plt.ylabel(ylab, fontsize=15)\n",
        "    plt.xticks(fontsize=12)\n",
        "    plt.yticks(fontsize=12)\n",
        "    for k, v in y.items():\n",
        "        plt.text(k,\n",
        "                 round(v),\n",
        "                 str(round(v)),\n",
        "                 fontsize=12,\n",
        "                 color='k',\n",
        "                 horizontalalignment='center',\n",
        "                 verticalalignment='bottom')\n",
        "    plt.show()\n",
        "\n",
        "def plot_metrics(res_pronos_df, plot_mercado_path, RE):\n",
        "    res_pronos_df = res_pronos_df.filter(regex=RE, axis=0)\n",
        "    res_pronos_df.sort_values(by=['MAE'], ascending=False).plot.barh(\n",
        "        y='MAE', legend=None, figsize=(15, len(res_pronos_df)))\n",
        "    plt.title(column.replace(\"_\", \" \") + '\\nError absoluto medio', size=18)\n",
        "    mae_plot_path = os.path.join(plot_mercado_path, \"MAE.png\")\n",
        "    plt.savefig(mae_plot_path)\n",
        "    plt.show()\n",
        "    res_pronos_df.sort_values(by=['MSE'], ascending=False).plot.barh(\n",
        "        y='MSE', legend=None, figsize=(15, len(res_pronos_df)))\n",
        "    plt.title(column.replace(\"_\", \" \") + '\\nError cuadrático medio', size=18)\n",
        "    mse_plot_path = os.path.join(plot_mercado_path, \"MSE.png\")\n",
        "    plt.savefig(mse_plot_path)\n",
        "    plt.show()\n",
        "    res_pronos_df.sort_values(by=['R2'], ascending=True).plot.barh(\n",
        "        y='R2', legend=None, figsize=(15, len(res_pronos_df)))\n",
        "    plt.title(column.replace(\"_\", \" \") + '\\nCoeficiente de determinación',\n",
        "              size=18)\n",
        "    r2_plot_path = os.path.join(plot_mercado_path, \"R2.png\")\n",
        "    plt.savefig(r2_plot_path)\n",
        "    plt.show()\n",
        "    res_pronos_df.sort_values(by=['EVS'], ascending=True).plot.barh(\n",
        "        y='EVS', legend=None, figsize=(15, len(res_pronos_df)))\n",
        "    plt.title(column.replace(\"_\", \" \") + '\\nVarianza explicada', size=18)\n",
        "    evs_plot_path = os.path.join(plot_mercado_path, \"EVS.png\")\n",
        "    plt.savefig(evs_plot_path)\n",
        "    plt.show()\n",
        "    res_pronos_df.sort_values(by=['ME'], ascending=False).plot.barh(\n",
        "        y='ME', legend=None, figsize=(15, len(res_pronos_df)))\n",
        "    plt.title(column.replace(\"_\", \" \") + '\\nError máximo', size=18)\n",
        "    me_plot_path = os.path.join(plot_mercado_path, \"ME.png\")\n",
        "    plt.savefig(me_plot_path)\n",
        "    plt.show()\n",
        "    res_pronos_df.sort_values(by=['MAPE'], ascending=False).plot.barh(\n",
        "        y='MAPE', legend=None, figsize=(15, len(res_pronos_df)))\n",
        "    plt.title(column.replace(\"_\", \" \") + '\\nError Porcentual Absoluto Medio',\n",
        "              size=18)\n",
        "    mape_plot_path = os.path.join(plot_mercado_path, \"MAPE.png\")\n",
        "    plt.savefig(mape_plot_path)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def tiempo_entrenamiento():\n",
        "    t_total = datetime.datetime.now() - tiempo_inicio_fit\n",
        "    print(\"\\n{}: Tiempo total:\\t{}\".format(datetime.datetime.now(),t_total))\n",
        "    res_tiempos['t_total'][nombre_modelo] = t_total.total_seconds()\n",
        "    time_tabla_path = os.path.join(tabla_mercado_path,nombre_modelo + \"_t.csv\")\n",
        "    res_tiempos_df = pd.DataFrame(res_tiempos)\n",
        "    res_tiempos_df.to_csv(time_tabla_path)\n",
        "    print(\"\\n{}: Guardando tiempo total en:\\t{}\\n\\n\".format(datetime.datetime.now(), time_tabla_path))\n",
        "\n",
        "def mk_model_dirs(name):\n",
        "    '''Crea las carpetas y los paths hacia las carpetas de los modelos'''\n",
        "    modelo_path = os.path.join(modelos_path, name)\n",
        "    tabla_path = os.path.join(tablas_path, name)\n",
        "    plot_path = os.path.join(plots_path, name)\n",
        "    # log_path = os.path.join(logs_path, name)\n",
        "    for model_dirs in [modelo_path, tabla_path, plot_path]:\n",
        "        if not os.path.exists(model_dirs):\n",
        "            try:\n",
        "                os.makedirs(model_dirs, 0o700)\n",
        "            except OSError as e:\n",
        "                if e.errno != errno.EEXIST:\n",
        "                    raise\n",
        "            print(\"Directorio creado: {}\".format(model_dirs))\n",
        "        else:\n",
        "            print(\"Directorio ya existente: {}\".format(model_dirs))\n",
        "    return modelo_path, tabla_path, plot_path\n",
        "\n",
        "\n",
        "def mk_model_mercado_dirs(mercado):\n",
        "    modelo_mercado_path = os.path.join(modelo_path, mercado)\n",
        "    tabla_mercado_path = os.path.join(tabla_path, mercado)\n",
        "    plot_mercado_path = os.path.join(plot_path, mercado)\n",
        "    # log_mercado_path = os.path.join(log_path, mercado)\n",
        "    for model_mercado_dirs in [\n",
        "            modelo_mercado_path, tabla_mercado_path, plot_mercado_path\n",
        "    ]:\n",
        "        if not os.path.exists(model_mercado_dirs):\n",
        "            try:\n",
        "                os.makedirs(model_mercado_dirs, 0o700)\n",
        "            except OSError as e:\n",
        "                if e.errno != errno.EEXIST:\n",
        "                    raise\n",
        "            print(\"Directorio creado: {}\".format(model_mercado_dirs))\n",
        "        else:\n",
        "            print(\"Directorio ya existente: {}\".format(model_mercado_dirs))\n",
        "    return modelo_mercado_path, tabla_mercado_path, plot_mercado_path\n",
        "\n",
        "\n",
        "\n",
        "def mk_dir(name):\n",
        "    '''crear el directorio con el nombre que le pasas'''\n",
        "    path = os.path.join(os.getcwd(), name)\n",
        "    if not os.path.exists(path):\n",
        "        try:\n",
        "            os.makedirs(path, 0o700)\n",
        "        except OSError as e:\n",
        "            if e.errno != errno.EEXIST:\n",
        "                raise\n",
        "        print(\"Directorio creado: {}\".format(path))\n",
        "    else:\n",
        "        print(\"Directorio ya existente: {}\".format(path))\n",
        "    return path\n",
        "\n",
        "def traducir_dia(text):\n",
        "    t = text.replace('Sunday', 'Domingo')\n",
        "    t = t.replace('Monday', 'Lunes')\n",
        "    t = t.replace('Tuesday', 'Martes')\n",
        "    t = t.replace('Wednesday', 'Miércoles')\n",
        "    t = t.replace('Thursday', 'Jueves')\n",
        "    t = t.replace('Friday', 'Viernes')\n",
        "    t = t.replace('Saturday', 'Sábado')\n",
        "    return t\n",
        "\n",
        "\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "def metrics_time_series(y_true, y_pred, resultados, modelo):\n",
        "    print(\"\\n{}: Evaluando pronósticos\".format(datetime.datetime.now()))\n",
        "    me = round(max_error(y_true, y_pred), 3)\n",
        "    r2 = round(r2_score(y_true, y_pred), 3)\n",
        "    evs = round(explained_variance_score(y_true, y_pred), 3)\n",
        "    mae = round(mean_absolute_error(y_true, y_pred), 3)\n",
        "    mse = round(mean_squared_error(y_true, y_pred), 3)\n",
        "    mape = round(mean_absolute_percentage_error(y_true, y_pred), 3)\n",
        "    print(f\"Error máximo: {me}\")\n",
        "    print(f\"Coeficiente de determinación (R2): {r2}\")\n",
        "    print(f\"Varianza explicada: {evs}\")\n",
        "    print(f\"Error cuadrático medio: {mse}\")\n",
        "    print(f\"Error absoluto medio: {mae}\")\n",
        "    print(f\"Error Porcentual Absoluto Medio: {mape}\")\n",
        "    resultados['ME'][modelo] = me\n",
        "    resultados['R2'][modelo] = r2\n",
        "    resultados['EVS'][modelo] = evs\n",
        "    resultados['MAE'][modelo] = mae\n",
        "    resultados['MSE'][modelo] = mse\n",
        "    resultados['MAPE'][modelo] = mape\n",
        "\n",
        "    metric_tabla_path = os.path.join(tabla_mercado_path, modelo + \"_m.csv\")\n",
        "    res_pronos_df = pd.DataFrame(resultados)\n",
        "    print(\"\\n{}: Guardando métricas en:\\t{}\".format(datetime.datetime.now(),metric_tabla_path))\n",
        "    res_pronos_df.filter(regex=RE, axis=0).to_csv(metric_tabla_path)\n",
        "\n",
        "\n",
        "def datos_supervisados(entrenamiento_esc, test_esc, pasado_historico):\n",
        "    x_entrenamiento, y_entrenamiento = [], []\n",
        "    for j in range(0, entrenamiento_esc.shape[0] - len(test_esc) + 1):\n",
        "        indices = range(j - pasado_historico, j, 1)\n",
        "        x_entrenamiento.append(\n",
        "            np.reshape(entrenamiento_esc[indices], (pasado_historico, 1)))\n",
        "        y_entrenamiento.append(entrenamiento_esc[j:j + len(test_esc)])\n",
        "    x_train = np.asarray(x_entrenamiento)\n",
        "    y_train = np.asarray(y_entrenamiento)\n",
        "    x_test = np.reshape(entrenamiento_esc[-pasado_historico:],\n",
        "                        (1, pasado_historico, 1))\n",
        "    y_test = np.reshape(test_esc, (1, test_esc.shape[0]))\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "def plot_history(history):\n",
        "    history_plot_path = os.path.join(plot_mercado_path, nombre_modelo + \"-history.png\")\n",
        "    plt.figure()\n",
        "    plt.xlabel('Épocas')\n",
        "    plt.ylabel('Error absoluto medio')\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.legend(['Entrenamiento', 'Validación'])\n",
        "    plt.title(nombre_modelo, size=24)\n",
        "    plt.savefig(history_plot_path)\n",
        "    plt.show()\n",
        "\n",
        "def mk_regexs(mercado):\n",
        "    regex_AUTOARIMA = re.compile(r'^' + mercado + '|^AUTOARIMA.+' +\n",
        "                                 mercado.replace(\"Precio_mercado_SPOT_\", \"\") +\n",
        "                                 \"$\")\n",
        "    regex_AR = re.compile(r'^' + mercado + '|^AR_p.+' +\n",
        "                          mercado.replace(\"Precio_mercado_SPOT_\", \"\") + \"$\")\n",
        "    regex_MA = re.compile(r'^' + mercado + '|^MA_q.+' +\n",
        "                          mercado.replace(\"Precio_mercado_SPOT_\", \"\") + \"$\")\n",
        "    regex_ARMA = re.compile(r'^' + mercado + '|^ARMA.+' +\n",
        "                            mercado.replace(\"Precio_mercado_SPOT_\", \"\") + \"$\")\n",
        "    regex_ARIMA = re.compile(r'^' + mercado + '|^ARIMA.+' +\n",
        "                             mercado.replace(\"Precio_mercado_SPOT_\", \"\") + \"$\")\n",
        "    regex_SARIMA = re.compile(r'^' + mercado + '|^SARIMA.+' +\n",
        "                              mercado.replace(\"Precio_mercado_SPOT_\", \"\") +\n",
        "                              \"$\")\n",
        "    regex_BATS = re.compile(r'^' + mercado + '|^BATS.+' +\n",
        "                            mercado.replace(\"Precio_mercado_SPOT_\", \"\") + \"$\")\n",
        "    regex_TBATS = re.compile(r'^' + mercado + '|^TBATS.+' +\n",
        "                             mercado.replace(\"Precio_mercado_SPOT_\", \"\") + \"$\")\n",
        "    regex_lstm_densa = re.compile(r'^' + mercado + '|^LSTM\\d+?_Densa\\d+?.+' +\n",
        "                                  mercado.replace('Precio_mercado_SPOT_', '') +\n",
        "                                  '$')\n",
        "    regex_lstm_densa_do = re.compile(\n",
        "        r'^' + mercado + '|^LSTM\\d+?_Densa\\d+?_DO\\d+?.+' +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_lstm_lstm_densa = re.compile(\n",
        "        r'^' + mercado + '|^LSTM\\d+?_LSTM\\d+?_Densa\\d+?.+' +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_lstm_lstm_densa_do = re.compile(\n",
        "        r'^' + mercado + '|^LSTM\\d+?_LSTM\\d+?_Densa\\d+?_DO\\d+?.+' +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_lstm_lstm_densa_densa = re.compile(\n",
        "        r'^' + mercado + '|^LSTM\\d+?_LSTM\\d+?_Densa\\d+?_Densa\\d+?.+' +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_lstm_lstm_densa_densa_do = re.compile(\n",
        "        r'^' + mercado + '|^LSTM\\d+?_LSTM\\d+?_Densa\\d+?_Densa\\d+?_DO\\d+?.+' +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_lstm_lstm_lstm_densa = re.compile(\n",
        "        r'^' + mercado + '|^LSTM\\d+?_LSTM\\d+?_LSTM\\d+?_Densa\\d+?.+' +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_lstm_lstm_lstm_densa_do = re.compile(\n",
        "        r'^' + mercado + '|^LSTM\\d+?_LSTM\\d+?_LSTM\\d+?_Densa\\d+?_DO\\d+?.+' +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_gru_flatten_densa = re.compile(\n",
        "        r'^' + mercado + '|^GRU\\d+?_Flatten_Densa\\d+?.+' +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_gru_do_flatten_densa = re.compile(\n",
        "        r'^' + mercado + '|^GRU\\d+?_DO\\d+?_Flatten_Densa\\d+?.+' +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_gru_gru_flatten_densa = re.compile(\n",
        "        r'^' + mercado + '|^GRU\\d+?_GRU\\d+?_Flatten_Densa\\d+?.+' +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_gru_do_gru_do_flatten_densa = re.compile(\n",
        "        r'^' + mercado +\n",
        "        '|^GRU\\d+?_DO\\d+?_GRU\\d+?_DO\\d+?_Flatten_Densa\\d+?.+' +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_gru_gru_flatten_densa_densa = re.compile(\n",
        "        r'^' + mercado + '|^GRU\\d+?_GRU\\d+?_Flatten_Densa\\d+?_Densa\\d+?.+' +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_gru_do_gru_do_flatten_densa_densa = re.compile(\n",
        "        r'^' + mercado +\n",
        "        '|^GRU\\d+?_DO\\d+?_GRU\\d+?_DO\\d+?_Flatten_Densa\\d+?_Densa\\d+?.+' +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_gru_gru_gru_flatten_densa = re.compile(\n",
        "        r'^' + mercado + '|^GRU\\d+?_GRU\\d+?_GRU\\d+?_Flatten_Densa\\d+?.+' +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_gru_do_gru_do_gru_do_flatten_densa = re.compile(\n",
        "        r'^' + mercado +\n",
        "        '|^GRU\\d+?_DO\\d+?_GRU\\d+?_DO\\d+?_GRU\\d+?_DO\\d+?_Flatten_Densa\\d+?.+' +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_conv1d_maxpool1d_flatten_densa = re.compile(\n",
        "        r'^' + mercado + '|^Conv1D\\d+?_MaxPool1D\\d+?_Flatten_Densa\\d+?.+' +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_conv1d_do_maxpool1d_flatten_densa = re.compile(\n",
        "        r'^' + mercado +\n",
        "        '|^Conv1D\\d+?_DO\\d+?_MaxPool1D\\d+?_Flatten_Densa\\d+?.+' +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_conv1d_maxpool1d_conv1d_maxpool1d_flatten_densa = re.compile(\n",
        "        r'^' + mercado +\n",
        "        '|^Conv1D\\d+?_MaxPool1D\\d+?_Conv1D\\d+?_MaxPool1D\\d+?_Flatten_Densa\\d+?.+'\n",
        "        + mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_conv1d_do_maxpool1d_conv1d_do_maxpool1d_flatten_densa = re.compile(\n",
        "        r'^' + mercado +\n",
        "        '|^Conv1D\\d+?_DO\\d+?_MaxPool1D\\d+?_Conv1D\\d+?_DO\\d+?_MaxPool1D\\d+?_Flatten_Densa\\d+?.+'\n",
        "        + mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_TCN_densa = re.compile(r'^' + mercado + '|^TCN\\d+?_Densa\\d+?.+' +\n",
        "                                 mercado.replace('Precio_mercado_SPOT_', '') +\n",
        "                                 '$')\n",
        "    regex_TCN_do_densa = re.compile(\n",
        "        r'^' + mercado + '|^TCN\\d+?_DO\\d+?_Densa\\d+?.+' +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_masking_lstm_densa = re.compile(\n",
        "        r\"^\" + mercado + \"|^Masking_LSTM\\d+?_Densa\\d+?\" +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_masking_lstm_densa_do = re.compile(\n",
        "        r\"^\" + mercado + \"|^Masking_LSTM\\d+?_Densa\\d+?_DO\\d+?\" +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_masking_lstm_lstm_densa = re.compile(\n",
        "        r\"^\" + mercado + \"|^Masking_LSTM\\d+?_LSTM\\d+?_Densa\\d+?\" +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_masking_lstm_lstm_densa_do = re.compile(\n",
        "        r\"^\" + mercado + \"|^Masking_LSTM\\d+?_LSTM\\d+?_Densa\\d+?_DO\\d+?\" +\n",
        "        mercado.replace(\"Perecio_mercado_SPOT_\", '') + \"$\")\n",
        "    regex_masking_lstm_lstm_densa_densa = re.compile(\n",
        "        r\"^\" + mercado + \"|^Masking_LSTM\\d+?_LSTM\\d+?_Densa\\d+?_Densa\\d+?\" +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_masking_lstm_lstm_densa_densa_do = re.compile(\n",
        "        r\"^\" + mercado +\n",
        "        \"|^Masking_LSTM\\d+?_LSTM\\d+?_Densa\\d+?_Densa\\d+?_DO\\d+?\" +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_masking_lstm_lstm_lstm_densa = re.compile(\n",
        "        r\"^\" + mercado + \"|^Masking_LSTM\\d+?_LSTM\\d+?_LSTM\\d+?_Densa\\d+?\" +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_masking_lstm_lstm_lstm_densa_do = re.compile(\n",
        "        r\"^\" + mercado +\n",
        "        \"|^Masking_LSTM\\d+?_LSTM\\d+?_LSTM\\d+?_Densa\\d+?_DO\\d+?\" +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_masking_gru_flatten_densa = re.compile(\n",
        "        r\"^\" + mercado + \"|^Masking_GRU\\d+?_Flatten_Densa\\d+?\" +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_masking_gru_do_flatten_densa = re.compile(\n",
        "        r\"^\" + mercado + \"|^Masking_GRU\\d+?_DO\\d+?_Flatten_Densa\\d+?\" +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_masking_gru_gru_flatten_densa = re.compile(\n",
        "        r\"^\" + mercado + \"|^Masking_GRU\\d+?_GRU\\d+?_Flatten_Densa\\d+?\" +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_masking_gru_do_gru_do_flatten_densa = re.compile(\n",
        "        r\"^\" + mercado +\n",
        "        \"|^Masking_GRU\\d+?_DO\\d+?_GRU\\d+?_DO\\d+?_Flatten_Densa\\d+?\" +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_masking_gru_gru_flatten_densa_densa = re.compile(\n",
        "        r\"^\" + mercado +\n",
        "        \"|^Masking_GRU\\d+?_GRU\\d+?_Flatten_Densa\\d+?_Densa\\d+?\" +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_masking_gru_do_gru_do_flatten_densa_densa = re.compile(\n",
        "        r\"^\" + mercado +\n",
        "        \"|^Masking_GRU\\d+?_DO\\d+?_GRU\\d+?_DO\\d+?_Flatten_Densa\\d+?_Densa\\d+?\" +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_masking_gru_gru_gru_flatten_densa = re.compile(\n",
        "        r\"^\" + mercado +\n",
        "        \"|^Masking_GRU\\d+?_GRU\\d+?_GRU\\d+?_Flatten_Densa\\d+?\" +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_masking_gru_do_gru_do_gru_do_flatten_densa = re.compile(\n",
        "        r\"^\" + mercado +\n",
        "        \"|^Masking_GRU\\d+?_DO\\d+?_GRU\\d+?_DO\\d+?_GRU\\d+?_DO\\d+?_Flatten_Densa\\d+?\"\n",
        "        + mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_masking_conv1d_maxpool1d_flatten_densa = re.compile(\n",
        "        r\"^\" + mercado +\n",
        "        \"|^Masking_Conv1D\\d+?_MaxPool1D\\d+?_Flatten_Densa\\d+?\" +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_masking_conv1d_do_maxpool1d_flatten_densa = re.compile(\n",
        "        r\"^\" + mercado +\n",
        "        \"|^Masking_Conv1D\\d+?_DO\\d+?_MaxPool1D\\d+?_Flatten_Densa\\d+?\" +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_masking_conv1d_maxpool1d_conv1d_maxpool1d_flatten_densa = re.compile(\n",
        "        r\"^\" + mercado +\n",
        "        \"|^Masking_Conv1D\\d+?_MaxPool1D\\d+?_Conv1D\\d+?_MaxPool1D\\d+?_Flatten_Densa\\d+?\"\n",
        "        + mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_masking_conv1d_do_maxpool1d_conv1d_do_maxpool1d_flatten_densa = re.compile(\n",
        "        r\"^\" + mercado +\n",
        "        \"|^Masking_Conv1D\\d+?_DO\\d+?_MaxPool1D\\d+?_Conv1D\\d+?_DO\\d+?_MaxPool1D\\d+?_Flatten_Densa\\d+?\"\n",
        "        + mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_masking_TCN_densa = re.compile(\n",
        "        r\"^\" + mercado + \"|^Masking_TCN\\d+?_Densa\\d+?\" +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    regex_masking_TCN_do_densa = re.compile(\n",
        "        r\"^\" + mercado + \"|^Masking_TCN\\d+?_DO\\d+?_Densa\\d+?\" +\n",
        "        mercado.replace('Precio_mercado_SPOT_', '') + '$')\n",
        "    return regex_AUTOARIMA, regex_AR, regex_MA, regex_ARMA, regex_ARIMA, regex_SARIMA, regex_BATS, regex_TBATS, regex_lstm_densa, regex_lstm_densa_do, regex_lstm_lstm_densa, regex_lstm_lstm_densa_do, regex_lstm_lstm_densa_densa, regex_lstm_lstm_densa_densa_do, regex_lstm_lstm_lstm_densa, regex_lstm_lstm_lstm_densa_do, regex_gru_flatten_densa, regex_gru_do_flatten_densa, regex_gru_gru_flatten_densa, regex_gru_do_gru_do_flatten_densa, regex_gru_gru_flatten_densa_densa, regex_gru_do_gru_do_flatten_densa_densa, regex_gru_gru_gru_flatten_densa, regex_gru_do_gru_do_gru_do_flatten_densa, regex_conv1d_maxpool1d_flatten_densa, regex_conv1d_do_maxpool1d_flatten_densa, regex_conv1d_maxpool1d_conv1d_maxpool1d_flatten_densa, regex_conv1d_do_maxpool1d_conv1d_do_maxpool1d_flatten_densa, regex_TCN_densa, regex_TCN_do_densa, regex_masking_lstm_densa, regex_masking_lstm_densa_do, regex_masking_lstm_lstm_densa, regex_masking_lstm_lstm_densa_do, regex_masking_lstm_lstm_densa_densa, regex_masking_lstm_lstm_densa_densa_do, regex_masking_lstm_lstm_lstm_densa, regex_masking_lstm_lstm_lstm_densa_do, regex_masking_gru_flatten_densa, regex_masking_gru_do_flatten_densa, regex_masking_gru_gru_flatten_densa, regex_masking_gru_do_gru_do_flatten_densa, regex_masking_gru_gru_flatten_densa_densa, regex_masking_gru_do_gru_do_flatten_densa_densa, regex_masking_gru_gru_gru_flatten_densa, regex_masking_gru_do_gru_do_gru_do_flatten_densa, regex_masking_conv1d_maxpool1d_flatten_densa, regex_masking_conv1d_do_maxpool1d_flatten_densa, regex_masking_conv1d_maxpool1d_conv1d_maxpool1d_flatten_densa, regex_masking_conv1d_do_maxpool1d_conv1d_do_maxpool1d_flatten_densa, regex_masking_TCN_densa, regex_masking_TCN_do_densa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO_n-WmCtdD8"
      },
      "source": [
        "### Funciones: Redes Neuronales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDFjox73tQAE"
      },
      "source": [
        "# 08- LSTM Densa\n",
        "# crear_lstm_densa\n",
        "def crear_lstm_densa(u_0,\n",
        "                     pasado_historico,\n",
        "                     horizonte_prevision,\n",
        "                     n_artributos=1):\n",
        "    \"\"\"crear_lstm_densa\"\"\"\n",
        "    model = Sequential(\n",
        "        name=\"LSTM{}_Densa{}\".format(u_0, horizonte_prevision))\n",
        "    model.add(\n",
        "        LSTM(units=u_0, input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "# crear_masking_lstm_densa\n",
        "def crear_masking_lstm_densa(u_0,\n",
        "                             pasado_historico,\n",
        "                             horizonte_prevision,\n",
        "                             n_artributos=1):\n",
        "    \"\"\"crear_masking_lstm_densa\"\"\"\n",
        "    model = Sequential(\n",
        "        name=\"Masking_LSTM{}_Densa{}\".format(u_0, horizonte_prevision))\n",
        "    model.add(\n",
        "        Masking(mask_value=-1, input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(LSTM(units=u_0))\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "# 09- LSTM Densa DO\n",
        "# crear_lstm_densa_do\n",
        "def crear_lstm_densa_do(u_0,\n",
        "                        pasado_historico,\n",
        "                        horizonte_prevision,\n",
        "                        dropout=0.1,\n",
        "                        n_artributos=1):\n",
        "    \"\"\"crear_lstm_densa_do\"\"\"\n",
        "    model = Sequential(name=\"LSTM{}_Densa{}_DO{}\".format(\n",
        "        u_0, horizonte_prevision, int(dropout * 100)))\n",
        "    model.add(\n",
        "        LSTM(units=u_0,\n",
        "             dropout=dropout,\n",
        "             input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# crear_masking_lstm_densa_do\n",
        "def crear_masking_lstm_densa_do(u_0,\n",
        "                                pasado_historico,\n",
        "                                horizonte_prevision,\n",
        "                                dropout=0.1,\n",
        "                                n_artributos=1):\n",
        "    \"\"\"crear_masking_lstm_densa_do\"\"\"\n",
        "    model = Sequential(name=\"Masking_LSTM{}_Densa{}_DO{}\".format(\n",
        "        u_0, horizonte_prevision, int(dropout * 100)))\n",
        "    model.add(\n",
        "        Masking(mask_value=-1, input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(LSTM(units=u_0, dropout=dropout))\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# 10- LSTM LSTM Densa\n",
        "# crear_lstm_lstm_densa\n",
        "def crear_lstm_lstm_densa(u_1,\n",
        "                          u_2,\n",
        "                          pasado_historico,\n",
        "                          horizonte_prevision,\n",
        "                          n_artributos=1):\n",
        "    \"\"\"crear_lstm_lstm_densa\"\"\"\n",
        "    model = Sequential(name=\"LSTM{}_LSTM{}_Densa{}\".format(\n",
        "        u_1, u_2, horizonte_prevision))\n",
        "    model.add(\n",
        "        LSTM(units=u_1,\n",
        "             return_sequences=True,\n",
        "             input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(LSTM(units=u_2))\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# crear_masking_lstm_lstm_densa\n",
        "def crear_masking_lstm_lstm_densa(u_1,\n",
        "                                  u_2,\n",
        "                                  pasado_historico,\n",
        "                                  horizonte_prevision,\n",
        "                                  n_artributos=1):\n",
        "    model = Sequential(name=\"Masking_LSTM{}_LSTM{}_Densa{}\".format(\n",
        "        u_1, u_2, horizonte_prevision))\n",
        "    model.add(\n",
        "        Masking(mask_value=-1, input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(LSTM(units=u_1, return_sequences=True))\n",
        "    model.add(LSTM(units=u_2))\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# 11- LSTM LSTM Densa_DO\n",
        "# crear_lstm_lstm_densa_do\n",
        "def crear_lstm_lstm_densa_do(u_1,\n",
        "                             u_2,\n",
        "                             pasado_historico,\n",
        "                             horizonte_prevision,\n",
        "                             dropout=0.1,\n",
        "                             n_artributos=1):\n",
        "    model = Sequential(name=\"LSTM{}_LSTM{}_Densa{}_DO{}\".format(\n",
        "        u_1, u_2, horizonte_prevision, int(dropout * 100)))\n",
        "    model.add(\n",
        "        LSTM(units=u_1,\n",
        "             dropout=dropout,\n",
        "             return_sequences=True,\n",
        "             input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(LSTM(units=u_2, dropout=dropout))\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# crear_masking_lstm_lstm_densa_do\n",
        "def crear_masking_lstm_lstm_densa_do(u_1,\n",
        "                                     u_2,\n",
        "                                     pasado_historico,\n",
        "                                     horizonte_prevision,\n",
        "                                     dropout=0.1,\n",
        "                                     n_artributos=1):\n",
        "    model = Sequential(name=\"Masking_LSTM{}_LSTM{}_Densa{}_DO{}\".format(\n",
        "        u_1, u_2, horizonte_prevision, int(dropout * 100)))\n",
        "    model.add(\n",
        "        Masking(mask_value=-1, input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(LSTM(units=u_1, dropout=dropout, return_sequences=True))\n",
        "    model.add(LSTM(units=u_2, dropout=dropout))\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# 12- LSTM LSTM Densa Densa\n",
        "# crear_lstm_lstm_densa_densa\n",
        "def crear_lstm_lstm_densa_densa(u_1,\n",
        "                                u_2,\n",
        "                                pasado_historico,\n",
        "                                horizonte_prevision,\n",
        "                                n_artributos=1):\n",
        "    model = Sequential(name=\"LSTM{}_LSTM{}_Densa{}_Densa{}\".format(\n",
        "        u_1, u_2, u_1, horizonte_prevision))\n",
        "    model.add(\n",
        "        LSTM(units=u_1,\n",
        "             return_sequences=True,\n",
        "             input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(LSTM(units=u_2))\n",
        "    model.add(Dense(units=u_1))\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# crear_masking_lstm_lstm_densa_densa\n",
        "def crear_masking_lstm_lstm_densa_densa(u_1,\n",
        "                                        u_2,\n",
        "                                        pasado_historico,\n",
        "                                        horizonte_prevision,\n",
        "                                        n_artributos=1):\n",
        "    model = Sequential(name=\"Masking_LSTM{}_LSTM{}_Densa{}_Densa{}\".format(\n",
        "        u_1, u_2, u_1, horizonte_prevision))\n",
        "    model.add(\n",
        "        Masking(mask_value=-1, input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(LSTM(units=u_1, return_sequences=True))\n",
        "    model.add(LSTM(units=u_2))\n",
        "    model.add(Dense(units=u_1))\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# 13- LSTM LSTM Densa Densa_DO\n",
        "# crear_lstm_lstm_densa_densa_do\n",
        "def crear_lstm_lstm_densa_densa_do(u_1,\n",
        "                                   u_2,\n",
        "                                   pasado_historico,\n",
        "                                   horizonte_prevision,\n",
        "                                   dropout=0.1,\n",
        "                                   n_artributos=1):\n",
        "    model = Sequential(name=\"LSTM{}_LSTM{}_Densa{}_Densa{}_DO{}\".format(\n",
        "        u_1, u_2, u_1, horizonte_prevision,\n",
        "        int(dropout * 100)))\n",
        "    model.add(\n",
        "        LSTM(units=u_1,\n",
        "             dropout=dropout,\n",
        "             return_sequences=True,\n",
        "             input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(LSTM(units=u_2, dropout=dropout))\n",
        "    model.add(Dense(units=u_1))\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# crear_masking_lstm_lstm_densa_densa_do\n",
        "def crear_masking_lstm_lstm_densa_densa_do(u_1,\n",
        "                                           u_2,\n",
        "                                           pasado_historico,\n",
        "                                           horizonte_prevision,\n",
        "                                           dropout=0.1,\n",
        "                                           n_artributos=1):\n",
        "    model = Sequential(\n",
        "        name=\"Masking_LSTM{}_LSTM{}_Densa{}_Densa{}_DO{}\".format(\n",
        "            u_1, u_2, u_1, horizonte_prevision,\n",
        "            int(dropout * 100)))\n",
        "    model.add(\n",
        "        Masking(mask_value=-1, input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(LSTM(units=u_1, dropout=dropout, return_sequences=True))\n",
        "    model.add(LSTM(units=u_2, dropout=dropout))\n",
        "    model.add(Dense(units=u_1))\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# 14- LSTM LSTM LSTM_Densa\n",
        "# crear_lstm_lstm_lstm_densa\n",
        "def crear_lstm_lstm_lstm_densa(u_1,\n",
        "                               u_2,\n",
        "                               u_3,\n",
        "                               pasado_historico,\n",
        "                               horizonte_prevision,\n",
        "                               n_artributos=1):\n",
        "    model = Sequential(name=\"LSTM{}_LSTM{}_LSTM{}_Densa{}\".format(\n",
        "        u_1, u_2, u_3, horizonte_prevision))\n",
        "    model.add(\n",
        "        LSTM(units=u_1,\n",
        "             return_sequences=True,\n",
        "             input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(LSTM(units=u_2, return_sequences=True))\n",
        "    model.add(LSTM(units=u_3))\n",
        "    model.add(Dense(units=u_1))\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# crear_masking_lstm_lstm_lstm_densa\n",
        "def crear_masking_lstm_lstm_lstm_densa(u_1,\n",
        "                                       u_2,\n",
        "                                       u_3,\n",
        "                                       pasado_historico,\n",
        "                                       horizonte_prevision,\n",
        "                                       n_artributos=1):\n",
        "    model = Sequential(name=\"Masking_LSTM{}_LSTM{}_LSTM{}_Densa{}\".format(\n",
        "        u_1, u_2, u_3, horizonte_prevision))\n",
        "    model.add(\n",
        "        Masking(mask_value=-1, input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(LSTM(units=u_1, return_sequences=True))\n",
        "    model.add(LSTM(units=u_2, return_sequences=True))\n",
        "    model.add(LSTM(units=u_3))\n",
        "    model.add(Dense(units=u_1))\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# 15- LSTM LSTM LSTM_Densa_DO\n",
        "# crear_lstm_lstm_lstm_densa_do\n",
        "def crear_lstm_lstm_lstm_densa_do(u_1,\n",
        "                                  u_2,\n",
        "                                  u_3,\n",
        "                                  pasado_historico,\n",
        "                                  horizonte_prevision,\n",
        "                                  dropout=0.1,\n",
        "                                  n_artributos=1):\n",
        "    model = Sequential(name=\"LSTM{}_LSTM{}_LSTM{}_Densa{}_DO{}\".format(\n",
        "        u_1, u_2, u_3, horizonte_prevision,\n",
        "        int(dropout * 100)))\n",
        "    model.add(\n",
        "        LSTM(units=u_1,\n",
        "             dropout=dropout,\n",
        "             return_sequences=True,\n",
        "             input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(LSTM(units=u_2, dropout=dropout, return_sequences=True))\n",
        "    model.add(LSTM(units=u_3, dropout=dropout))\n",
        "    model.add(Dense(units=u_1))\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# crear_masking_lstm_lstm_lstm_densa_do\n",
        "def crear_masking_lstm_lstm_lstm_densa_do(u_1,\n",
        "                                          u_2,\n",
        "                                          u_3,\n",
        "                                          pasado_historico,\n",
        "                                          horizonte_prevision,\n",
        "                                          dropout=0.1,\n",
        "                                          n_artributos=1):\n",
        "    model = Sequential(name=\"Masking_LSTM{}_LSTM{}_LSTM{}_Densa{}_DO{}\".format(\n",
        "        u_1, u_2, u_3, horizonte_prevision,\n",
        "        int(dropout * 100)))\n",
        "    model.add(\n",
        "        Masking(mask_value=-1, input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(LSTM(units=u_1, dropout=dropout, return_sequences=True))\n",
        "    model.add(LSTM(units=u_2, dropout=dropout, return_sequences=True))\n",
        "    model.add(LSTM(units=u_3, dropout=dropout))\n",
        "    model.add(Dense(units=u_1))\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# 16- GRU Flatten Densa\n",
        "# crear_gru_flatten_densa\n",
        "def crear_gru_flatten_densa(u_0,\n",
        "                            pasado_historico,\n",
        "                            horizonte_prevision,\n",
        "                            n_artributos=1):\n",
        "    model = Sequential(\n",
        "        name=\"GRU{}_Flatten_Densa{}\".format(u_0, horizonte_prevision))\n",
        "    model.add(GRU(units=u_0,\n",
        "                  input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# crear_masking_gru_flatten_densa\n",
        "def crear_masking_gru_flatten_densa(u_0,\n",
        "                                    pasado_historico,\n",
        "                                    horizonte_prevision,\n",
        "                                    n_artributos=1):\n",
        "    model = Sequential(name=\"Masking_GRU{}_Flatten_Densa{}\".format(\n",
        "        u_0, horizonte_prevision))\n",
        "    model.add(\n",
        "        Masking(mask_value=-1, input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(GRU(units=u_0))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# 17- GRU DO Flatten Densa\n",
        "# crear_gru_do_flatten_densa\n",
        "def crear_gru_do_flatten_densa(u_0,\n",
        "                               pasado_historico,\n",
        "                               horizonte_prevision,\n",
        "                               dropout=0.1,\n",
        "                               n_artributos=1):\n",
        "    model = Sequential(name=\"GRU{}_DO{}_Flatten_Densa{}\".format(\n",
        "        u_0, int(dropout * 100), horizonte_prevision))\n",
        "    model.add(GRU(units=u_0,\n",
        "                  input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(Dropout(rate=dropout, seed=1))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# crear_masking_gru_do_flatten_densa\n",
        "def crear_masking_gru_do_flatten_densa(u_0,\n",
        "                                       pasado_historico,\n",
        "                                       horizonte_prevision,\n",
        "                                       dropout=0.1,\n",
        "                                       n_artributos=1):\n",
        "    model = Sequential(name=\"Masking_GRU{}_DO{}_Flatten_Densa{}\".format(\n",
        "        u_0, horizonte_prevision, int(dropout * 100)))\n",
        "    model.add(\n",
        "        Masking(mask_value=-1, input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(GRU(units=u_0, dropout=dropout))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# 18- GRU GRU Flatten Densa\n",
        "# crear_gru_gru_flatten_densa\n",
        "def crear_gru_gru_flatten_densa(u_1,\n",
        "                                u_2,\n",
        "                                pasado_historico,\n",
        "                                horizonte_prevision,\n",
        "                                n_artributos=1):\n",
        "    model = Sequential(name=\"GRU{}_GRU{}_Flatten_Densa{}\".format(\n",
        "        u_1, u_2, horizonte_prevision))\n",
        "    model.add(\n",
        "        GRU(units=u_1,\n",
        "            return_sequences=True,\n",
        "            input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(GRU(units=u_2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# crear_masking_gru_gru_flatten_densa\n",
        "def crear_masking_gru_gru_flatten_densa(u_1,\n",
        "                                        u_2,\n",
        "                                        pasado_historico,\n",
        "                                        horizonte_prevision,\n",
        "                                        n_artributos=1):\n",
        "    model = Sequential(name=\"Masking_GRU{}_GRU{}_Flatten_Densa{}\".format(\n",
        "        u_1, u_2, horizonte_prevision))\n",
        "    model.add(\n",
        "        Masking(mask_value=-1, input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(GRU(units=u_1, return_sequences=True))\n",
        "    model.add(GRU(units=u_2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# 19- GRU DO GRU DO Flatten Densa\n",
        "# crear_gru_do_gru_do_flatten_densa\n",
        "def crear_gru_do_gru_do_flatten_densa(u_1,\n",
        "                                      u_2,\n",
        "                                      pasado_historico,\n",
        "                                      horizonte_prevision,\n",
        "                                      dropout=0.1,\n",
        "                                      n_artributos=1):\n",
        "    model = Sequential(name=\"GRU{}_DO{}_GRU{}_DO{}_Flatten_Densa{}\".format(\n",
        "        u_1, int(dropout * 100), \n",
        "        u_2, int(dropout * 100), \n",
        "        horizonte_prevision))\n",
        "    model.add(GRU(units=u_1,\n",
        "                  return_sequences=True,\n",
        "                  input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(Dropout(rate=dropout, seed=1))\n",
        "    model.add(GRU(units=u_2))\n",
        "    model.add(Dropout(rate=dropout, seed=1))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# crear_masking_gru_gru_flatten_densa_do\n",
        "def crear_masking_gru_do_gru_do_flatten_densa(u_1,\n",
        "                                              u_2,\n",
        "                                              pasado_historico,\n",
        "                                              horizonte_prevision,\n",
        "                                              dropout=0.1,\n",
        "                                              n_artributos=1):\n",
        "    model = Sequential(name=\"Masking_GRU{}_DO{}_GRU{}_DO{}_Flatten_Densa{}\".format(\n",
        "        u_1, int(dropout * 100), \n",
        "        u_2, int(dropout * 100), \n",
        "        horizonte_prevision))\n",
        "    model.add(Masking(mask_value=-1, \n",
        "                      input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(GRU(units=u_1, dropout=dropout, return_sequences=True))\n",
        "    model.add(GRU(units=u_2, dropout=dropout))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# 20- GRU GRU Flatten Densa_Densa\n",
        "# crear_gru_gru_flatten_densa_densa\n",
        "def crear_gru_gru_flatten_densa_densa(u_1,\n",
        "                                      u_2,\n",
        "                                      pasado_historico,\n",
        "                                      horizonte_prevision,\n",
        "                                      n_artributos=1):\n",
        "    model = Sequential(name=\"GRU{}_GRU{}_Flatten_Densa{}_Densa{}\".format(\n",
        "        u_1, u_2, u_1, horizonte_prevision))\n",
        "    model.add(\n",
        "        GRU(units=u_1,\n",
        "            return_sequences=True,\n",
        "            input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(GRU(units=u_2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=u_1))\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# crear_masking_gru_gru_flatten_densa_densa\n",
        "def crear_masking_gru_gru_flatten_densa_densa(u_1,\n",
        "                                              u_2,\n",
        "                                              pasado_historico,\n",
        "                                              horizonte_prevision,\n",
        "                                              n_artributos=1):\n",
        "    model = Sequential(\n",
        "        name=\"Masking_GRU{}_GRU{}_Flatten_Densa{}_Densa{}\".format(\n",
        "            u_1, u_2, u_1, horizonte_prevision))\n",
        "    model.add(\n",
        "        Masking(mask_value=-1, input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(GRU(units=u_1, return_sequences=True))\n",
        "    model.add(GRU(units=u_2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=u_1))\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# 21- GRU GRU Flatten Densa_Densa_DO\n",
        "# crear_gru_do_gru_do_flatten_densa_densa\n",
        "def crear_gru_do_gru_do_flatten_densa_densa(u_1,\n",
        "                                            u_2,\n",
        "                                            pasado_historico,\n",
        "                                            horizonte_prevision,\n",
        "                                            dropout=0.1,\n",
        "                                            n_artributos=1):\n",
        "    model = Sequential(\n",
        "        name=\"GRU{}_DO{}_GRU{}_DO{}_Flatten_Densa{}_Densa{}\".format(\n",
        "            u_1, int(dropout * 100), u_2, int(dropout * 100),\n",
        "            u_1, horizonte_prevision))\n",
        "    model.add(\n",
        "        GRU(units=u_1,\n",
        "            return_sequences=True,\n",
        "            input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(Dropout(rate=dropout, seed=1))\n",
        "    model.add(GRU(units=u_2))\n",
        "    model.add(Dropout(rate=dropout, seed=1))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=u_1))\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# crear_masking_gru_gru_flatten_densa_densa_do\n",
        "def crear_masking_gru_do_gru_do_flatten_densa_densa(u_1,\n",
        "                                                    u_2,\n",
        "                                                    pasado_historico,\n",
        "                                                    horizonte_prevision,\n",
        "                                                    dropout=0.1,\n",
        "                                                    n_artributos=1):\n",
        "    model = Sequential(\n",
        "        name=\"Masking_GRU{}_DO{}_GRU{}_DO{}_Flatten_Densa{}_Densa{}\".format(\n",
        "            u_1, int(dropout * 100), u_2, int(dropout * 100),\n",
        "            u_1, horizonte_prevision))\n",
        "    model.add(\n",
        "        Masking(mask_value=-1, input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(GRU(units=u_1, dropout=dropout, return_sequences=True))\n",
        "    model.add(GRU(units=u_2, dropout=dropout))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=u_1))\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# 22- GRU GRU GRU Flatten Densa\n",
        "# crear_gru_gru_gru_flatten_densa\n",
        "def crear_gru_gru_gru_flatten_densa(u_1,\n",
        "                                    u_2,\n",
        "                                    u_3,\n",
        "                                    pasado_historico,\n",
        "                                    horizonte_prevision,\n",
        "                                    n_artributos=1):\n",
        "    model = Sequential(name=\"GRU{}_GRU{}_GRU{}_Flatten_Densa{}\".format(\n",
        "        u_1, u_2, u_3, horizonte_prevision))\n",
        "    model.add(\n",
        "        GRU(units=u_1,\n",
        "            return_sequences=True,\n",
        "            input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(GRU(units=u_2, return_sequences=True))\n",
        "    model.add(GRU(units=u_3))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# crear_masking_gru_gru_gru_flatten_densa\n",
        "def crear_masking_gru_gru_gru_flatten_densa(u_1,\n",
        "                                            u_2,\n",
        "                                            u_3,\n",
        "                                            pasado_historico,\n",
        "                                            horizonte_prevision,\n",
        "                                            n_artributos=1):\n",
        "    model = Sequential(name=\"Masking_GRU{}_GRU{}_GRU{}_Flatten_Densa{}\".format(\n",
        "        u_1, u_2, u_3, horizonte_prevision))\n",
        "    model.add(\n",
        "        Masking(mask_value=-1, input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(GRU(units=u_1, return_sequences=True))\n",
        "    model.add(GRU(units=u_2, return_sequences=True))\n",
        "    model.add(GRU(units=u_3))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# 23- GRU GRU GRU Flatten Densa_DO\n",
        "# crear_gru_do_gru_do_gru_do_flatten_densa\n",
        "def crear_gru_do_gru_do_gru_do_flatten_densa(u_1,\n",
        "                                             u_2,\n",
        "                                             u_3,\n",
        "                                             pasado_historico,\n",
        "                                             horizonte_prevision,\n",
        "                                             dropout=0.1,\n",
        "                                             n_artributos=1):\n",
        "    model = Sequential(\n",
        "        name=\"GRU{}_DO{}_GRU{}_DO{}_GRU{}_DO{}_Flatten_Densa{}\".format(\n",
        "            u_1, int(dropout * 100), u_2, int(dropout * 100),\n",
        "            u_3, int(dropout * 100), horizonte_prevision))\n",
        "    model.add(\n",
        "        GRU(units=u_1,\n",
        "            return_sequences=True,\n",
        "            input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(Dropout(rate=dropout, seed=1))\n",
        "    model.add(GRU(units=u_2, return_sequences=True))\n",
        "    model.add(Dropout(rate=dropout, seed=1))\n",
        "    model.add(GRU(units=u_3))\n",
        "    model.add(Dropout(rate=dropout, seed=1))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# crear_masking_gru_do_gru_do_gru_do_flatten_densa\n",
        "def crear_masking_gru_do_gru_do_gru_do_flatten_densa(u_1,\n",
        "                                                     u_2,\n",
        "                                                     u_3,\n",
        "                                                     pasado_historico,\n",
        "                                                     horizonte_prevision,\n",
        "                                                     dropout=0.1,\n",
        "                                                     n_artributos=1):\n",
        "    model = Sequential(\n",
        "        name=\"Masking_GRU{}_DO{}_GRU{}_DO{}_GRU{}_DO{}_Flatten_Densa{}\".format(\n",
        "            u_1, int(dropout * 100), u_2, int(dropout * 100),\n",
        "            u_3, int(dropout * 100), horizonte_prevision))\n",
        "    model.add(\n",
        "        Masking(mask_value=-1, input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(GRU(units=u_1, dropout=dropout, return_sequences=True))\n",
        "    model.add(GRU(units=u_2, dropout=dropout, return_sequences=True))\n",
        "    model.add(GRU(units=u_3, dropout=dropout))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# 24- Conv1D MaxPool1D Flatten Densa\n",
        "# crear_conv1d_maxpool1d_flatten_densa\n",
        "def crear_conv1d_maxpool1d_flatten_densa(u_1,\n",
        "                                         pasado_historico,\n",
        "                                         horizonte_prevision,\n",
        "                                         n_artributos=1):\n",
        "    model = Sequential(name=\"Conv1D{}_MaxPool1D{}_Flatten_Densa{}\".format(\n",
        "        u_1, 2, horizonte_prevision))\n",
        "    model.add(\n",
        "        Conv1D(filters=u_1,\n",
        "               kernel_size=7,\n",
        "               padding='same',\n",
        "               activation='relu',\n",
        "               input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(MaxPool1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# crear_masking_conv1d_maxpool1d_flatten_densa\n",
        "def crear_masking_conv1d_maxpool1d_flatten_densa(u_1,\n",
        "                                                 pasado_historico,\n",
        "                                                 horizonte_prevision,\n",
        "                                                 n_artributos=1):\n",
        "    model = Sequential(\n",
        "        name=\"Masking_Conv1D{}_MaxPool1D{}_Flatten_Densa{}\".format(\n",
        "            u_1, 2, horizonte_prevision))\n",
        "    model.add(\n",
        "        Masking(mask_value=-1, input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(\n",
        "        Conv1D(filters=u_1,\n",
        "               kernel_size=7,\n",
        "               padding='same',\n",
        "               activation='relu',\n",
        "               input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(MaxPool1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "#### 25- Conv1D_DO_MaxPool1D_Flatten_Densa\n",
        "# crear_conv1d_DO_maxpool1d_flatten_densa\n",
        "def crear_conv1d_do_maxpool1d_flatten_densa(u_1,\n",
        "                                            pasado_historico,\n",
        "                                            horizonte_prevision,\n",
        "                                            dropout=0.1,\n",
        "                                            n_artributos=1):\n",
        "    model = Sequential(name=\"Conv1D{}_DO{}_MaxPool1D{}_Flatten_Densa{}\".format(\n",
        "        u_1, int(dropout * 100), 2, horizonte_prevision))\n",
        "    model.add(\n",
        "        Conv1D(filters=u_1,\n",
        "               kernel_size=7,\n",
        "               padding='same',\n",
        "               activation='relu',\n",
        "               input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(Dropout(rate=dropout, seed=1))\n",
        "    model.add(MaxPool1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# crear_masking_conv1d_DO_maxpool1d_flatten_densa\n",
        "def crear_masking_conv1d_do_maxpool1d_flatten_densa(u_1,\n",
        "                                                    pasado_historico,\n",
        "                                                    horizonte_prevision,\n",
        "                                                    dropout=0.1,\n",
        "                                                    n_artributos=1):\n",
        "    model = Sequential(\n",
        "        name=\"Masking_Conv1D{}_DO{}_MaxPool1D{}_Flatten_Densa{}\".format(\n",
        "            u_1, int(dropout * 100), 2, horizonte_prevision))\n",
        "    model.add(\n",
        "        Masking(mask_value=-1, input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(\n",
        "        Conv1D(filters=u_1,\n",
        "               kernel_size=7,\n",
        "               padding='same',\n",
        "               activation='relu',\n",
        "               input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(Dropout(rate=dropout, seed=1))\n",
        "    model.add(MaxPool1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# 26- Conv1D MaxPool1D Conv1D MaxPool1D Flatten Densa\n",
        "# crear_conv1d_maxpool1d_conv1d_maxpool1d_flatten_densa\n",
        "def crear_conv1d_maxpool1d_conv1d_maxpool1d_flatten_densa(\n",
        "        u_1,\n",
        "        u_2,\n",
        "        pasado_historico,\n",
        "        horizonte_prevision,\n",
        "        n_artributos=1):\n",
        "    model = Sequential(\n",
        "        name=\"Conv1D{}_MaxPool1D{}_Conv1D{}_MaxPool1D{}_Flatten_Densa{}\".\n",
        "        format(u_1, 2, u_2, 2, horizonte_prevision))\n",
        "    model.add(\n",
        "        Conv1D(filters=u_1,\n",
        "               kernel_size=7,\n",
        "               padding='same',\n",
        "               activation='relu',\n",
        "               input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(MaxPool1D(pool_size=2))\n",
        "    model.add(\n",
        "        Conv1D(filters=u_2,\n",
        "               kernel_size=5,\n",
        "               padding='same',\n",
        "               activation='relu'))\n",
        "    model.add(MaxPool1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# crear_masking_conv1d_maxpool1d_conv1d_maxpool1d_flatten_densa\n",
        "def crear_masking_conv1d_maxpool1d_conv1d_maxpool1d_flatten_densa(\n",
        "        u_1,\n",
        "        u_2,\n",
        "        pasado_historico,\n",
        "        horizonte_prevision,\n",
        "        n_artributos=1):\n",
        "    model = Sequential(\n",
        "        name=\"Masking_Conv1D{}_MaxPool1D{}_Conv1D{}_MaxPool1D{}_Flatten_Densa{}\"\n",
        "        .format(u_1, 2, u_2, 2, horizonte_prevision))\n",
        "    model.add(\n",
        "        Masking(mask_value=-1, input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(\n",
        "        Conv1D(filters=u_1,\n",
        "               kernel_size=7,\n",
        "               padding='same',\n",
        "               activation='relu'))\n",
        "    model.add(MaxPool1D(pool_size=2))\n",
        "    model.add(\n",
        "        Conv1D(filters=u_2,\n",
        "               kernel_size=5,\n",
        "               padding='same',\n",
        "               activation='relu'))\n",
        "    model.add(MaxPool1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# 27- Conv1D DO MaxPool1D Conv1D DO MaxPool1D Flatten Densa\n",
        "# crear_conv1d_do_maxpool1d_conv1d_do_maxpool1d_flatten_densa\n",
        "def crear_conv1d_do_maxpool1d_conv1d_do_maxpool1d_flatten_densa(\n",
        "        u_1,\n",
        "        u_2,\n",
        "        pasado_historico,\n",
        "        horizonte_prevision,\n",
        "        dropout=0.1,\n",
        "        n_artributos=1):\n",
        "    model = Sequential(\n",
        "        name=\n",
        "        \"Conv1D{}_DO{}_MaxPool1D{}_Conv1D{}_DO{}_MaxPool1D{}_Flatten_Densa{}\".\n",
        "        format(u_1, int(dropout * 100), 2, u_2, int(\n",
        "            dropout * 100), 2, horizonte_prevision))\n",
        "    model.add(\n",
        "        Conv1D(filters=u_1,\n",
        "               kernel_size=7,\n",
        "               padding='same',\n",
        "               activation='relu',\n",
        "               input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(Dropout(rate=dropout))\n",
        "    model.add(MaxPool1D(pool_size=2))\n",
        "    model.add(\n",
        "        Conv1D(filters=u_2,\n",
        "               kernel_size=5,\n",
        "               padding='same',\n",
        "               activation='relu'))\n",
        "    model.add(Dropout(rate=dropout))\n",
        "    model.add(MaxPool1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# crear_masking_conv1d_do_maxpool1d_conv1d_do_maxpool1d_flatten_densa\n",
        "def crear_masking_conv1d_do_maxpool1d_conv1d_do_maxpool1d_flatten_densa(\n",
        "        u_1,\n",
        "        u_2,\n",
        "        pasado_historico,\n",
        "        horizonte_prevision,\n",
        "        dropout=0.1,\n",
        "        n_artributos=1):\n",
        "    model = Sequential(\n",
        "        name=\n",
        "        \"Masking_Conv1D{}_DO{}_MaxPool1D{}_Conv1D{}_DO{}_MaxPool1D{}_Flatten_Densa{}\"\n",
        "        .format(u_1, int(dropout * 100), 2, u_2,\n",
        "                int(dropout * 100), 2, horizonte_prevision))\n",
        "    model.add(\n",
        "        Masking(mask_value=-1, input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(\n",
        "        Conv1D(filters=u_1,\n",
        "               kernel_size=7,\n",
        "               padding='same',\n",
        "               activation='relu'))\n",
        "    model.add(Dropout(rate=dropout))\n",
        "    model.add(MaxPool1D(pool_size=2))\n",
        "    model.add(\n",
        "        Conv1D(filters=u_2,\n",
        "               kernel_size=5,\n",
        "               padding='same',\n",
        "               activation='relu'))\n",
        "    model.add(Dropout(rate=dropout))\n",
        "    model.add(MaxPool1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "#### 28- TCN_Densa\n",
        "# crear_TCN_densa\n",
        "def crear_TCN_densa(u_0,\n",
        "                    pasado_historico,\n",
        "                    horizonte_prevision,\n",
        "                    n_artributos=1):\n",
        "    model = Sequential(\n",
        "        name=\"TCN{}_Densa{}\".format(u_0, horizonte_prevision))\n",
        "    model.add(InputLayer(input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(\n",
        "        TCN(nb_filters=u_0,\n",
        "            kernel_size=3,\n",
        "            nb_stacks=1,\n",
        "            dilations=[1, 2, 4, 8, 16, 32, 64]))\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# crear_masking_TCN_densa\n",
        "def crear_masking_TCN_densa(u_0,\n",
        "                            pasado_historico,\n",
        "                            horizonte_prevision,\n",
        "                            n_artributos=1):\n",
        "    model = Sequential(\n",
        "        name=\"Masking_TCN{}_Densa{}\".format(u_0, horizonte_prevision))\n",
        "    model.add(\n",
        "        Masking(mask_value=-1, input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(\n",
        "        TCN(nb_filters=u_0,\n",
        "            kernel_size=3,\n",
        "            nb_stacks=1,\n",
        "            dilations=[1, 2, 4, 8, 16, 32, 64]))\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# 29- TCN DO Densa\n",
        "# crear_TCN_do_densa\n",
        "def crear_TCN_do_densa(u_0,\n",
        "                       pasado_historico,\n",
        "                       horizonte_prevision,\n",
        "                       dropout=0.1,\n",
        "                       n_artributos=1):\n",
        "    model = Sequential(name=\"TCN{}_DO{}_Densa{}\".format(\n",
        "        u_0, int(dropout * 100), horizonte_prevision))\n",
        "    model.add(InputLayer(input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(\n",
        "        TCN(nb_filters=u_0,\n",
        "            kernel_size=3,\n",
        "            nb_stacks=1,\n",
        "            dilations=[1, 2, 4, 8, 16, 32, 64]))\n",
        "    model.add(Dropout(rate=dropout))\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "# crear_masking_TCN_do_densa\n",
        "def crear_masking_TCN_do_densa(u_0,\n",
        "                               pasado_historico,\n",
        "                               horizonte_prevision,\n",
        "                               dropout=0.1,\n",
        "                               n_artributos=1):\n",
        "    model = Sequential(name=\"Masking_TCN{}_DO{}_Densa{}\".format(\n",
        "        u_0, int(dropout * 100), horizonte_prevision))\n",
        "    model.add(\n",
        "        Masking(mask_value=-1, input_shape=(pasado_historico, n_artributos)))\n",
        "    model.add(\n",
        "        TCN(nb_filters=u_0,\n",
        "            kernel_size=3,\n",
        "            nb_stacks=1,\n",
        "            dilations=[1, 2, 4, 8, 16, 32, 64]))\n",
        "    model.add(Dropout(rate=dropout))\n",
        "    model.add(Dense(units=horizonte_prevision))\n",
        "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
        "    print(model.summary())\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sGeAR_nfEvt"
      },
      "source": [
        "# Directorios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owbr73xtfEvt"
      },
      "source": [
        "# Definir el directorio de trabajo\n",
        "cwd = \"/content/drive/MyDrive/Colab Notebooks/DUMMY_NUMBERS_2\"\n",
        "os.chdir(cwd)\n",
        "print(cwd)\n",
        "\n",
        "# Crear directorios\n",
        "data_path = mk_dir(\"00-data\")\n",
        "plots_path = mk_dir(\"01-plots\")\n",
        "modelos_path = mk_dir(\"02-modelos\")\n",
        "tablas_path = mk_dir(\"03-tablas\")\n",
        "sumario_path = mk_dir(\"04-sumario\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBeCXSUUqsc1"
      },
      "source": [
        "# Importar datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GrBLkI9WlKW"
      },
      "source": [
        "# from google.colab import files\n",
        "# df = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9Hflw73tgl0"
      },
      "source": [
        "# Importing dataset\n",
        "df = pd.read_excel(\n",
        "    '/content/drive/MyDrive/Colab Notebooks/DUMMY_NUMBERS_2/DEALS_DETAIL-DUMMY_NUMBERS.xlsx')\n",
        "\n",
        "# Eliminar la columna Negocio - Título\n",
        "df.drop('Negocio - Título', axis=1, inplace=True)\n",
        "df.columns = [\n",
        "    'Creado_el', 'Fecha_ganado', 'Origen', 'CAC', 'Vehículo', 'Contratación',\n",
        "    'Tipo_cliente', 'Kilometraje', 'Plazo', 'PFF', 'Cuota', 'Comisión_fija',\n",
        "    'Comision_variable', 'Comsión_total']\n",
        "\n",
        "df['Vehículo'] = df['Vehículo'].str.replace('Modelo ', '')\n",
        "\n",
        "# convertir las 'Negocio - Negocio creado el' al formato 'datetime' de pandas\n",
        "df['Creado_el'] = pd.to_datetime(df['Creado_el'], format='%Y-%m-%d %H:%M:%S')\n",
        "# convertir las 'Negocio - Fecha de ganado' al formato 'datetime' de pandas\n",
        "df['Fecha_ganado'] = pd.to_datetime(df['Fecha_ganado'],\n",
        "                                    format='%Y-%m-%d %H:%M:%S')\n",
        "# ordenar datos por 'Fecha_creado'\n",
        "df.sort_values(by=['Creado_el'], inplace=True, ascending=True)\n",
        "\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Echemos un vistazo al conjunto de datos\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4dMD4ApprJd"
      },
      "source": [
        "# CANTIDAD DE VENTAS POR FECHA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQQEStfW0ggC"
      },
      "source": [
        "df_fecha_cant = df.resample(\n",
        "    \"D\", on='Creado_el').count()['Comsión_total'].to_frame(name=\"Num_ventas\")\n",
        "plt.plot(df_fecha_cant)\n",
        "plt.xticks(pd.date_range(df_fecha_cant.index.min(),\n",
        "                         df_fecha_cant.index.max(),\n",
        "                         freq='7D'),\n",
        "           rotation='vertical',\n",
        "           size=9)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6s-psVgeWuiQ"
      },
      "source": [
        "df_fecha_cant"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhjI55BSp01p"
      },
      "source": [
        "# COMISIONES POR FECHA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9Co8BR37J04"
      },
      "source": [
        "df_fecha_com = df.resample(\n",
        "    \"D\", on='Creado_el').sum()['Comsión_total'].to_frame(name=\"Comisiones_dia\")\n",
        "plt.plot(df_fecha_com)\n",
        "plt.xticks(pd.date_range(df_fecha_com.index.min(),\n",
        "                         df_fecha_com.index.max(),\n",
        "                         freq='7D'),\n",
        "           rotation='vertical', size=9)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhPAI14DWqOG"
      },
      "source": [
        "df_fecha_com"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJazieeHXbCX"
      },
      "source": [
        "df_ = pd.concat([df_fecha_com, df_fecha_cant], axis=1)\n",
        "df_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrBn23OTEN3O"
      },
      "source": [
        "# CANTIDAD DE VENTAS POR DÍA DE LA SEMANA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-skH-b5PvF6D"
      },
      "source": [
        "df_fecha_cant['Día_de_la_semana'] = df_fecha_cant.index.day_name()\n",
        "df_fecha_cant['Día_de_la_semana'] = df_fecha_cant['Día_de_la_semana'].apply(\n",
        "    lambda x: traducir_dia(x))\n",
        "\n",
        "dias = ['Lunes', 'Martes', 'Miércoles', 'Jueves', 'Viernes', 'Sábado', 'Domingo']\n",
        "\n",
        "df_dia_cant = df_fecha_cant.groupby('Día_de_la_semana').sum()['Num_ventas'].to_frame(name=\"Num_ventas\").reindex(dias)\n",
        "\n",
        "print(df_dia_cant)\n",
        "\n",
        "plot_bar(df_dia_cant.index, df_dia_cant[\"Num_ventas\"],\n",
        "         \"CANTIDAD DE VENTAS POR DÍA DE LA SEMANA\", \n",
        "         \"DÍA DE LA SEMANA\",\n",
        "         \"Número de ventas\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu5RJs_PMgNN"
      },
      "source": [
        "plot_pie_cant(df_dia_cant.index, df_dia_cant[\"Num_ventas\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZAryOlsEvyN"
      },
      "source": [
        "# COMISIONES POR DÍA DE LA SEMANA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYGWr2EyILQs"
      },
      "source": [
        "df_fecha_com['Día_de_la_semana'] = df_fecha_com.index.day_name()\n",
        "df_fecha_com['Día_de_la_semana'] = df_fecha_com['Día_de_la_semana'].apply(lambda x: traducir_dia(x))\n",
        "df_dia_com = df_fecha_com.groupby('Día_de_la_semana').sum()['Comisiones_dia'].to_frame(name=\"Comisiones_dia\").reindex(dias)\n",
        "print(df_dia_com)\n",
        "plot_bar(df_dia_com.index, df_dia_com[\"Comisiones_dia\"], \n",
        "         \"COMISIONES TOTALES POR DÍA DE LA SEMANA\", \n",
        "         \"DÍA DE LA SEMANA\", \n",
        "         \"COMISIONES\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_H3Rz8WBB2t"
      },
      "source": [
        "plot_pie_comi(df_dia_com.index, df_dia_com[\"Comisiones_dia\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThTVdLdXRoJY"
      },
      "source": [
        "\n",
        "# **Predicciones**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nefSZBF3L4Kp"
      },
      "source": [
        "horizonte_prevision = 7\n",
        "\n",
        "# Seleccionamos los datos a partir del día 2020-06-17\n",
        "#df = df_fecha_cant.loc[(df_fecha_cant.index > \"2020-06-17\"),[\"Num_ventas\"]]\n",
        "df = df_.loc[(df_.index > \"2020-06-01\"),]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaU4G499YjV4"
      },
      "source": [
        "\n",
        "for column in tqdm_notebook(df.columns):\n",
        "    print(column)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0mhM05qu38S"
      },
      "source": [
        "# MODELOS TRADICIONALES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6nkFS8dQmix"
      },
      "source": [
        "## 00- AUTOARIMA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaFK8TuIFbBq"
      },
      "source": [
        "dir_modelo = \"00-AUTOARIMA\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "\n",
        "    # Regex para filtrar los resultados\n",
        "    RE = re.compile(r'^AUTOARIMA.+' + column + \"$\")\n",
        "\n",
        "    # Directorios de modelo y mercado/s\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "\n",
        "    # datos de entrenamiento y testeo\n",
        "    df_train = df[[column]].iloc[:-horizonte_prevision].copy()\n",
        "    df_test = df[[column]].iloc[-horizonte_prevision:].copy()\n",
        "    tiempo_inicio_fit = datetime.datetime.now()\n",
        "\n",
        "    # Nombre de modelo\n",
        "    nombre_modelo = \"AUTOARIMA-\" + column\n",
        "    print(\"\\n\\n{}: Modelo \\t{}\".format(tiempo_inicio_fit, nombre_modelo))\n",
        "\n",
        "    # Ruta al modelo\n",
        "    path_modelo = os.path.join(modelo_mercado_path, nombre_modelo + \".pkl\")\n",
        "    if os.path.isfile(path_modelo):  # Si el modelo existe\n",
        "        # Cargar modelo\n",
        "        print(\"\\n{}: Cargando modelo:\\t{}\".format(datetime.datetime.now(),path_modelo))\n",
        "        AUTOARIMA = pickle.load(open(path_modelo, 'rb'))\n",
        "    else:\n",
        "        # Crear modelo\n",
        "        print(\"\\n{}: Inicio entrenamiento\".format(datetime.datetime.now()))\n",
        "        AUTOARIMA = auto_arima(df_train[column].values)\n",
        "        # Guardar modelo\n",
        "        print(\"\\n{}: Guardando modelo:\\t{}\".format(datetime.datetime.now(),path_modelo))\n",
        "        pickle.dump(AUTOARIMA, open(path_modelo, 'wb'))\n",
        "        # Tiempo de entrenamiento\n",
        "        tiempo_entrenamiento()\n",
        "\n",
        "    # Sumario\n",
        "    print(\"\\n{}: SUMARIO:\\n{}\".format(datetime.datetime.now(), AUTOARIMA.summary()))\n",
        "\n",
        "    # Diagnósticos\n",
        "    diagnostic(AUTOARIMA)\n",
        "\n",
        "    # Parámetros\n",
        "    print(\"\\n{}: Parámetros:\\n{}\".format(datetime.datetime.now(), AUTOARIMA.get_params()))\n",
        "\n",
        "    # Pronóstico\n",
        "    fc = prediction(AUTOARIMA)\n",
        "\n",
        "    # Plot pronóstico\n",
        "    plot_pronos(df_test, nombre_modelo, column)\n",
        "\n",
        "    # Métricas\n",
        "    metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "\n",
        "    gc.collect()\n",
        "    \n",
        "    # Plot Métricas\n",
        "    plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28cnaeLE9Js1"
      },
      "source": [
        "## 01- AR\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0Sd1Ndma7HV"
      },
      "source": [
        "dir_modelo = \"01-AR\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "    # Regex para filtrar los resultados\n",
        "    RE = re.compile(r'^AR.+' + column + \"$\")\n",
        "    # Directorios de modelo y mercado/s\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    # datos de entrenamiento y testeo\n",
        "    df_train = df[[column]].dropna().iloc[:-horizonte_prevision].copy()\n",
        "    df_test = df[[column]].dropna().iloc[-horizonte_prevision:].copy()\n",
        "    for p in tqdm_notebook(range(1, 3)):\n",
        "        tiempo_inicio_fit = datetime.datetime.now()\n",
        "\n",
        "        # Nombre de modelo\n",
        "        nombre_modelo = 'AR_p{:02d}-{}'.format(p, column)\n",
        "        print(\"\\n\\n{}: Modelo \\t{}\".format(datetime.datetime.now(),\n",
        "                                           nombre_modelo))\n",
        "\n",
        "        # Ruta al modelo\n",
        "        path_modelo = os.path.join(modelo_mercado_path, nombre_modelo + \".pkl\")\n",
        "        if os.path.isfile(path_modelo):  # Si el modelo existe\n",
        "\n",
        "            # Cargar modelo\n",
        "            print(\"\\n{}: Cargando modelo:\\t{}\".format(datetime.datetime.now(),\n",
        "                                                      path_modelo))\n",
        "            AR_result = pickle.load(open(path_modelo, 'rb'))\n",
        "        else:  # Si el modelo no existe\n",
        "            # Crear modelo\n",
        "            AR = ARMA(df_train[column], order=(p, 0))\n",
        "\n",
        "            # Entrenar modelo\n",
        "            print(\"\\n{}: Inicio entrenamiento\".format(datetime.datetime.now()))\n",
        "            AR_result = AR.fit()\n",
        "\n",
        "            # Guardar modelo\n",
        "            print(\"\\n{}: Guardando modelo:\\t{}\".format(datetime.datetime.now(),\n",
        "                                                       path_modelo))\n",
        "            AR_result.save(path_modelo)\n",
        "            pickle.dump(AR_result, open(path_modelo, 'wb'))\n",
        "\n",
        "            # Tiempo de entrenamiento\n",
        "            tiempo_entrenamiento()\n",
        "\n",
        "        # Sumario\n",
        "        print(\"\\n{}: Sumario:\\n{}\".format(datetime.datetime.now(), AR_result.summary()))\n",
        "\n",
        "        # Plot predicción\n",
        "        AR_result.plot_predict()\n",
        "        plt.show()\n",
        "\n",
        "        # Pronóstico\n",
        "        fc = forecast(AR_result)\n",
        "\n",
        "        # Plot pronóstico\n",
        "        plot_pronos(df_test, nombre_modelo, column)\n",
        "\n",
        "        # Métricas\n",
        "        metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "\n",
        "        gc.collect()\n",
        "    # Plot Métricas\n",
        "    plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CWPj4axF798"
      },
      "source": [
        "## 02- MA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iwFU6zEFbB-"
      },
      "source": [
        "dir_modelo = \"02-MA\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "    # Regex para filtrar los resultados\n",
        "    RE = re.compile(r'^MA.+' + column + \"$\")\n",
        "    # Directorios de modelo y mercado/s\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    # datos de entrenamiento y testeo\n",
        "    df_train = df[[column]].dropna().iloc[:-horizonte_prevision].copy()\n",
        "    df_test = df[[column]].dropna().iloc[-horizonte_prevision:].copy()\n",
        "    for q in tqdm_notebook(range(1, 4)):\n",
        "        try:\n",
        "            tiempo_inicio_fit = datetime.datetime.now()\n",
        "            # Nombre de modelo\n",
        "            nombre_modelo = 'MA_q{:02d}-{}'.format(q, column)\n",
        "            # Ruta al modelo\n",
        "            path_modelo = os.path.join(modelo_mercado_path,\n",
        "                                       nombre_modelo + \".pkl\")\n",
        "            if os.path.isfile(path_modelo):  # Si el modelo existe\n",
        "                # Cargar modelo\n",
        "                print(\"\\n{}: Cargando modelo:\\t{}\".format(\n",
        "                    datetime.datetime.now(), path_modelo))\n",
        "                MA_result = pickle.load(open(path_modelo, 'rb'))\n",
        "            else:  # Si el modelo no existe\n",
        "                # Crear modelo\n",
        "                MA = ARMA(df_train[column], order=(0, q))\n",
        "                # Entrenar modelo\n",
        "                print(\"\\n{}: Inicio entrenamiento\".format(\n",
        "                    datetime.datetime.now()))\n",
        "                MA_result = MA.fit()\n",
        "                # Guardar modelo\n",
        "                print(\"\\n{}: Guardando modelo:\\t{}\".format(\n",
        "                    datetime.datetime.now(), path_modelo))\n",
        "                MA_result.save(path_modelo)\n",
        "                pickle.dump(MA_result, open(path_modelo, 'wb'))\n",
        "                # Tiempo de entrenamiento\n",
        "                tiempo_entrenamiento()\n",
        "\n",
        "            # Sumario\n",
        "            print(\"\\n{}: Sumario:\\n{}\".format(datetime.datetime.now(), MA_result.summary()))\n",
        "\n",
        "            # Pronóstico\n",
        "            fc = forecast(MA_result)\n",
        "\n",
        "            # Plot predicción\n",
        "            MA_result.plot_predict(start=pd.to_datetime(\"2020-09-01\"))\n",
        "            plt.show()\n",
        "\n",
        "            # Plot pronóstico\n",
        "            plot_pronos(df_test, nombre_modelo, column)\n",
        "\n",
        "            # Métricas\n",
        "            metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "\n",
        "            gc.collect()\n",
        "        except:\n",
        "            continue\n",
        "    \n",
        "    # Plot Métricas\n",
        "    plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHO3_X27Ukbk"
      },
      "source": [
        "## 03- ARMA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHE5nFHmeA5i"
      },
      "source": [
        "p = q = range(1, 3)\n",
        "pq = list(itertools.product(p, q))\n",
        "dir_modelo = \"03-ARMA\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "    # Regex para filtrar los resultados\n",
        "    RE = re.compile(r'^ARMA.+' + column + \"$\")\n",
        "    # Directorios de modelo y mercado/s\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    # datos de entrenamiento y testeo\n",
        "    df_train = df[[column]].dropna().iloc[:-horizonte_prevision].copy()\n",
        "    df_test = df[[column]].dropna().iloc[-horizonte_prevision:].copy()\n",
        "    for parameters in tqdm_notebook(pq):\n",
        "        try:\n",
        "            tiempo_inicio_fit = datetime.datetime.now()\n",
        "            # Nombre de modelo\n",
        "            nombre_modelo = 'ARMA_p{:02d}q{:02d}-{}'.format(\n",
        "                parameters[0], parameters[1], column)\n",
        "            print(\"\\n\\n{}: Modelo \\t{}\".format(datetime.datetime.now(),\n",
        "                                               nombre_modelo))\n",
        "            # Ruta al modelo\n",
        "            path_modelo = os.path.join(modelo_mercado_path,\n",
        "                                       nombre_modelo + \".pkl\")\n",
        "\n",
        "            if os.path.isfile(path_modelo):  # Si el modelo existe\n",
        "                # Cargar modelo\n",
        "                print(\"\\n{}: Cargando modelo:\\t{}\".format(\n",
        "                    datetime.datetime.now(), path_modelo))\n",
        "                ARMA_result = ARIMAResults.load(path_modelo)\n",
        "            else:  # Si el modelo no existe\n",
        "                # Crear modelo\n",
        "                ARMA_ = ARMA(df_train[column], order=parameters)\n",
        "                print(\"\\n{}: Inicio entrenamiento\".format(\n",
        "                    datetime.datetime.now()))\n",
        "                # Entrenar modelo\n",
        "                ARMA_result = ARMA_.fit()\n",
        "                # Guardar modelo\n",
        "                print(\"\\n{}: Guardando modelo:\\t{}\".format(\n",
        "                    datetime.datetime.now(), path_modelo))\n",
        "                ARMA_result.save(path_modelo)\n",
        "\n",
        "                # Tiempo de entrenamiento\n",
        "                tiempo_entrenamiento()\n",
        "\n",
        "            # Sumario\n",
        "            print(\"\\n{}: Sumario:\\n{}\".format(datetime.datetime.now(), ARMA_result.summary()))\n",
        "\n",
        "            # Pronóstico\n",
        "            fc = forecast(ARMA_result)\n",
        "\n",
        "            # Plot pronóstico\n",
        "            plot_pronos(df_test, nombre_modelo, column)\n",
        "\n",
        "            # Métricas\n",
        "            metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "\n",
        "            gc.collect()\n",
        "        except:\n",
        "            continue\n",
        "    # Plot Métricas\n",
        "    try:\n",
        "        plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)\n",
        "    except:\n",
        "        continue    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H76DQjrBleOf"
      },
      "source": [
        "## 04- ARIMA\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-T7bC2kc-QJ"
      },
      "source": [
        "p = d = q = range(0, 3)\n",
        "pdq = list(itertools.product(p, d, q))\n",
        "dir_modelo = \"04-ARIMA\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "    # Regex para filtrar los resultados\n",
        "    RE = re.compile(r'^ARIMA.+' + column + \"$\")\n",
        "    # Directorios de modelo y mercado/s\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    # datos de entrenamiento y testeo\n",
        "    df_train = df[[column]].dropna().iloc[:-horizonte_prevision].copy()\n",
        "    df_test = df[[column]].dropna().iloc[-horizonte_prevision:].copy()\n",
        "    for parameters in pdq:\n",
        "        try:\n",
        "            tiempo_inicio_fit = datetime.datetime.now()\n",
        "            # Nombre de modelo\n",
        "            nombre_modelo = 'ARIMA_p{:02d}d{:02d}q{:02d}-{}'.format(\n",
        "                parameters[0], parameters[1], parameters[2], column)\n",
        "            print(\"\\n\\n{}: Modelo \\t{}\".format(datetime.datetime.now(),\n",
        "                                               nombre_modelo))\n",
        "            # Ruta al modelo\n",
        "            path_modelo = os.path.join(modelo_mercado_path,\n",
        "                                       nombre_modelo + \".pkl\")\n",
        "            if os.path.isfile(path_modelo):  # Si el modelo existe\n",
        "                # Cargar modelo\n",
        "                print(\"\\n{}: Cargando modelo:\\t{}\".format(\n",
        "                    datetime.datetime.now(), path_modelo))\n",
        "                ARIMA_result = ARIMAResults.load(path_modelo)\n",
        "            else:  # Si el modelo no existe\n",
        "                # Crear modelo\n",
        "                ARIMA_ = ARIMA(df_train[column], order=parameters)\n",
        "                print(\"\\n{}: Inicio entrenamiento\".format(\n",
        "                    datetime.datetime.now()))\n",
        "                # Entrenar modelo\n",
        "                ARIMA_result = ARIMA_.fit()\n",
        "                # Guardar modelo\n",
        "                print(\"\\n{}: Guardando modelo:\\t{}\".format(\n",
        "                    datetime.datetime.now(), path_modelo))\n",
        "                ARIMA_result.save(path_modelo)\n",
        "                # Tiempo de entrenamiento\n",
        "                tiempo_entrenamiento()\n",
        "            # Sumario\n",
        "            print(\"\\n{}: Sumario:\\n{}\".format(datetime.datetime.now(),ARIMA_result.summary()))\n",
        "\n",
        "            # Pronóstico\n",
        "            fc = forecast(ARIMA_result)\n",
        "    \n",
        "            # Plot pronóstico\n",
        "            plot_pronos(df_test, nombre_modelo, column)\n",
        "            \n",
        "            # Métricas\n",
        "            metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "\n",
        "            gc.collect()\n",
        "        except:\n",
        "            continue\n",
        "    # Plot Métricas\n",
        "    try:\n",
        "        # Plot Métricas\n",
        "        plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)\n",
        "    except:\n",
        "        continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCqUk_ACGCa0"
      },
      "source": [
        "## 05- SARIMA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPW6O9kdnAAV"
      },
      "source": [
        "p = d = q = range(0, 2)\n",
        "pdq = list(itertools.product(p, d, q))\n",
        "seasonal_pdq_comb = [(i[0], i[1], i[2], 7)\n",
        "                     for i in list(itertools.product(p, d, q))]\n",
        "\n",
        "dir_modelo = \"05-SARIMA\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "    # Regex para filtrar los resultados\n",
        "    RE = re.compile(r'^SARIMA.+' + column + \"$\")\n",
        "    # Directorios de modelo y mercado/s\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    # datos de entrenamiento y testeo\n",
        "    df_train = df[[column]].dropna().iloc[:-horizonte_prevision].copy()\n",
        "    df_test = df[[column]].dropna().iloc[-horizonte_prevision:].copy()\n",
        "    for parameters in tqdm_notebook(pdq):\n",
        "        for seasonal_param in tqdm_notebook(seasonal_pdq_comb):\n",
        "            try:\n",
        "                tiempo_inicio_fit = datetime.datetime.now()\n",
        "                # Nombre de modelo\n",
        "                nombre_modelo = 'SARIMA_p{:02d}d{:02d}q{:02d}P{:02d}D{:02d}Q{:02d}S{:02d}-{}'.format(\n",
        "                    parameters[0], parameters[1], parameters[2],\n",
        "                    seasonal_param[0], seasonal_param[1], seasonal_param[2],\n",
        "                    seasonal_param[3], column)\n",
        "                print(\"\\n\\n{}: Modelo \\t{}\".format(datetime.datetime.now(),\n",
        "                                                   nombre_modelo))\n",
        "                # Ruta al modelo\n",
        "                path_modelo = os.path.join(modelo_mercado_path,\n",
        "                                           nombre_modelo + \".pkl\")\n",
        "                # Si el modelo existe\n",
        "                if os.path.isfile(path_modelo):\n",
        "                    # Cargar modelo\n",
        "                    print(\"\\n{}: Cargando modelo:\\t{}\".format(\n",
        "                        datetime.datetime.now(), path_modelo))\n",
        "                    SARIMA_result = SARIMAXResults.load(path_modelo)\n",
        "                else:  # Si el modelo no existe\n",
        "                    # Crear modelo\n",
        "                    SARIMA = SARIMAX(df_train[column],\n",
        "                                     order=parameters,\n",
        "                                     seasonal_param_order=seasonal_param,\n",
        "                                     enforce_stationarity=False,\n",
        "                                     enforce_invertibility=False)\n",
        "                    print(\"\\n{}: Inicio entrenamiento\".format(\n",
        "                        datetime.datetime.now()))\n",
        "                    # Entrenar modelo\n",
        "                    SARIMA_result = SARIMA.fit()\n",
        "                    # Guardar modelo\n",
        "                    print(\"\\n{}: Guardando modelo:\\t{}\".format(\n",
        "                        datetime.datetime.now(), path_modelo))\n",
        "                    SARIMA_result.save(path_modelo)\n",
        "                    # Tiempo de entrenamiento\n",
        "                    tiempo_entrenamiento()\n",
        "\n",
        "                # Sumario\n",
        "                print(\"\\n{}: Sumario:\\n{}\".format(datetime.datetime.now(), SARIMA_result.summary()))\n",
        "\n",
        "                # Pronóstico\n",
        "                fc = forecast(SARIMA_result)\n",
        "                \n",
        "                # Plot pronóstico\n",
        "                plot_pronos(df_test, nombre_modelo, column)\n",
        "                \n",
        "                # Predicción\n",
        "                plot_pronos_sarima(SARIMA_result, df_test[[\"Num_ventas\"]])\n",
        "                \n",
        "                # Métricas\n",
        "                metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "                gc.collect()\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "    try:\n",
        "        # Plot Métricas\n",
        "        plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)\n",
        "    except:\n",
        "        continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jomf6tCjTKZf"
      },
      "source": [
        "## 06- BATS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKQKDbUvUl-w"
      },
      "source": [
        "dir_modelo = \"06-BATS\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "\n",
        "    # Regex para filtrar los resultados\n",
        "    RE = re.compile(r'^BATS.+' + column +\n",
        "                    \"$\")\n",
        "    # Directorios de modelo y mercado/s\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    # datos de entrenamiento y testeo\n",
        "    df_train = df[[column]].dropna().iloc[:-horizonte_prevision].copy()\n",
        "    df_test = df[[column]].dropna().iloc[-horizonte_prevision:].copy()\n",
        "    periodo_1 = 7\n",
        "    periodo_2 = 2 * 7\n",
        "    try:\n",
        "        tiempo_inicio_fit = datetime.datetime.now()\n",
        "        # Nombre de modelo\n",
        "        nombre_modelo = \"BATS_\"+'%i' % periodo_1+\"_\"+'%i' % periodo_2 + \\\n",
        "            \"-\"+column\n",
        "        print(\"\\n\\n{}: Modelo \\t{}\".format(datetime.datetime.now(),\n",
        "                                           nombre_modelo))\n",
        "        # Ruta al modelo\n",
        "        path_modelo = os.path.join(modelo_mercado_path, nombre_modelo + \".pkl\")\n",
        "\n",
        "        if os.path.isfile(path_modelo):  # Si el modelo existe\n",
        "            # Cargar modelo\n",
        "            print(\"\\n{}: Cargando modelo:\\t{}\".format(datetime.datetime.now(),\n",
        "                                                      path_modelo))\n",
        "            BATS_result = pickle.load(open(path_modelo, 'rb'))\n",
        "        else:  # Si el modelo no existe\n",
        "            # Crear modelo\n",
        "            BATS_ = BATS(seasonal_periods=(periodo_1, periodo_2))\n",
        "            print(\"\\n{}: Inicio entrenamiento\".format(datetime.datetime.now()))\n",
        "            # Entrenar modelo\n",
        "            BATS_result = BATS_.fit(df_train[column])\n",
        "            # Guardar modelo\n",
        "            print(\"\\n{}: Guardando modelo:\\t{}\".format(datetime.datetime.now(),\n",
        "                                                       path_modelo))\n",
        "            pickle.dump(BATS_result, open(path_modelo, 'wb'))\n",
        "\n",
        "            # Tiempo de entrenamiento\n",
        "            tiempo_entrenamiento()\n",
        "\n",
        "        # Pronóstico\n",
        "        forecast_bats(BATS_result)\n",
        "        \n",
        "        # Plot pronóstico\n",
        "        plot_pronos(df_test, nombre_modelo, column)\n",
        "\n",
        "        # Métricas\n",
        "        metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "\n",
        "        gc.collect()\n",
        "    except:\n",
        "        continue\n",
        "    # Plot Métricas\n",
        "    try:\n",
        "        plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)\n",
        "    except:\n",
        "        continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XW_dgMdHGXG"
      },
      "source": [
        "## 07- TBATS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2ztYT5KM_Ra"
      },
      "source": [
        "dir_modelo = \"07-TBATS\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "\n",
        "    # Regex para filtrar los resultados\n",
        "    RE = re.compile(r'^TBATS.+' + column +\n",
        "                    \"$\")\n",
        "    # Directorios de modelo y mercado/s\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    # datos de entrenamiento y testeo\n",
        "    df_train = df[[column]].dropna().iloc[:-horizonte_prevision].copy()\n",
        "    df_test = df[[column]].dropna().iloc[-horizonte_prevision:].copy()\n",
        "    periodo_1 = 7\n",
        "    periodo_2 = 2 * 7\n",
        "    try:\n",
        "        tiempo_inicio_fit = datetime.datetime.now()\n",
        "        # Nombre de modelo\n",
        "        nombre_modelo = \"TBATS_\"+'%i' % periodo_1+\"_\"+'%i' % periodo_2 + \\\n",
        "            \"-\"+column\n",
        "        print(\"\\n\\n{}: Modelo \\t{}\".format(datetime.datetime.now(),\n",
        "                                           nombre_modelo))\n",
        "        # Ruta al modelo\n",
        "        path_modelo = os.path.join(modelo_mercado_path, nombre_modelo + \".pkl\")\n",
        "\n",
        "        if os.path.isfile(path_modelo):  # Si el modelo existe\n",
        "            # Cargar modelo\n",
        "            print(\"\\n{}: Cargando modelo:\\t{}\".format(datetime.datetime.now(),\n",
        "                                                      path_modelo))\n",
        "            TBATS_result = pickle.load(open(path_modelo, 'rb'))\n",
        "        else:  # Si el modelo no existe\n",
        "            # Crear modelo\n",
        "            TBATS_ = TBATS(seasonal_periods=(periodo_1, periodo_2))\n",
        "            print(\"\\n{}: Inicio entrenamiento\".format(datetime.datetime.now()))\n",
        "            # Entrenar modelo\n",
        "            TBATS_result = TBATS_.fit(df_train[column])\n",
        "            # Guardar modelo\n",
        "            print(\"\\n{}: Guardando modelo:\\t{}\".format(datetime.datetime.now(),\n",
        "                                                       path_modelo))\n",
        "            pickle.dump(TBATS_result, open(path_modelo, 'wb'))\n",
        "\n",
        "            # Tiempo de entrenamiento\n",
        "            tiempo_entrenamiento()\n",
        "\n",
        "        # Pronóstico\n",
        "        forecast_bats(TBATS_result)\n",
        "\n",
        "        # Plot pronóstico\n",
        "        plot_pronos(df_test, nombre_modelo, column)\n",
        "\n",
        "        # Métricas\n",
        "        metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "\n",
        "        gc.collect()\n",
        "    except:\n",
        "        continue\n",
        "    # Plot Métricas\n",
        "    try:\n",
        "        plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)\n",
        "    except:\n",
        "        continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSS6_LaW1qh_"
      },
      "source": [
        "# REDES NEURONALES RECURRENTES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0MWHFhxbWu5"
      },
      "source": [
        "pasado_historico = 7*4\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "mis_callbacks = [EarlyStopping(monitor='val_loss', patience=3, mode='min', restore_best_weights=True)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLHqN-SCptQV"
      },
      "source": [
        "## Long short-term memory "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx1cJWdNQmjG"
      },
      "source": [
        "### 08- LSTM Densa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBx2Ims7QmjG"
      },
      "source": [
        "dir_modelo = \"08-LSTM_Densa\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    dataset = scaler.fit_transform(df[[column]])\n",
        "    test = dataset[-horizonte_prevision:]\n",
        "    train = dataset[:-horizonte_prevision]\n",
        "    x_train, y_train, x_test, y_test = datos_supervisados(\n",
        "        train, test, pasado_historico)\n",
        "    df_test = df[[column]].iloc[-horizonte_prevision:].copy()\n",
        "    for u_0 in tqdm_notebook([32, 64]):\n",
        "        for batch_size in tqdm_notebook([128]):\n",
        "            tiempo_inicio_fit = datetime.datetime.now()\n",
        "            match = re.search(\"[3-7]\", column)\n",
        "            if not match:\n",
        "                RE = re.compile(r'^LSTM\\d+?_Densa\\d+?.+' +\n",
        "                                column +\n",
        "                                '$')\n",
        "                # with tpu_strategy.scope():\n",
        "                model = crear_lstm_densa(u_0,\n",
        "                                         pasado_historico,\n",
        "                                         horizonte_prevision,\n",
        "                                         n_artributos=1)\n",
        "            else:\n",
        "                RE = re.compile(r'^Masking_LSTM\\d+?_Densa\\d+?.+' +\n",
        "                                column +\n",
        "                                '$')\n",
        "                # with tpu_strategy.scope():\n",
        "                model = crear_masking_lstm_densa(u_0,\n",
        "                                                 pasado_historico,\n",
        "                                                 horizonte_prevision,\n",
        "                                                 n_artributos=1)\n",
        "            # Nombre de modelo\n",
        "            nombre_modelo = '{}_batch{}-{}'.format(\n",
        "                model.name, batch_size,\n",
        "                column)\n",
        "            print(\"\\n\\n{}: Modelo \\t{}\".format(datetime.datetime.now(),\n",
        "                                               nombre_modelo))\n",
        "            # Ruta al modelo\n",
        "            path_modelo = os.path.join(modelo_mercado_path,\n",
        "                                       nombre_modelo + \".h5\")\n",
        "            if os.path.isfile(path_modelo):\n",
        "                # Cargar modelo\n",
        "                print(\"\\n{}: Cargando modelo:\\t{}\".format(\n",
        "                    datetime.datetime.now(), path_modelo))\n",
        "                model = keras.models.load_model(path_modelo)\n",
        "            else:\n",
        "                # Entrenar modelo\n",
        "                history = fit_model(x_train, y_train, batch_size)\n",
        "                \n",
        "                # Tiempo de entrenamiento\n",
        "                tiempo_entrenamiento()\n",
        "\n",
        "                # Guardar modelo\n",
        "                print(\"\\n{}: Guardando modelo:\\t{}\".format(\n",
        "                    datetime.datetime.now(), path_modelo))\n",
        "                model.save(path_modelo)\n",
        "                \n",
        "                # Plot history\n",
        "                plot_history(history)\n",
        "\n",
        "            # Info del modelo\n",
        "            print(\"\\n{}: Configuración del modelo:\".format(datetime.datetime.now()))\n",
        "            pprint.pprint(model.get_config())            \n",
        "\n",
        "            # Pronóstico\n",
        "            fc = forecast_nn()\n",
        "\n",
        "            # Plot pronóstico\n",
        "            plot_pronos(df_test, nombre_modelo, column)\n",
        "\n",
        "            # Métricas\n",
        "            metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "            gc.collect()\n",
        "    plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czOiMggZ7nUh"
      },
      "source": [
        "### 09- LSTM Densa DO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsHCtPKD-_Qy"
      },
      "source": [
        "dir_modelo = \"09-LSTM_Densa_DO\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    \n",
        "    dataset = scaler.fit_transform(df[[column]])\n",
        "    test = dataset[-horizonte_prevision:]\n",
        "    train = dataset[:-horizonte_prevision]\n",
        "    x_train, y_train, x_test, y_test = datos_supervisados(\n",
        "        train, test, pasado_historico)\n",
        "    df_test = df[[column]].iloc[-horizonte_prevision:].copy()\n",
        "    for u_0 in tqdm_notebook([32, 64]):\n",
        "        for batch_size in tqdm_notebook([128]):\n",
        "            tiempo_inicio_fit = datetime.datetime.now()\n",
        "            match = re.search(\"[3-7]\", column)\n",
        "            if not match:\n",
        "                RE = re.compile(r'^LSTM\\d+?_Densa\\d+?_DO.+' +\n",
        "                                column +\n",
        "                                '$')\n",
        "                # with tpu_strategy.scope():\n",
        "                model = crear_lstm_densa_do(u_0,\n",
        "                                            pasado_historico,\n",
        "                                            horizonte_prevision,\n",
        "                                            dropout=0.1,\n",
        "                                            n_artributos=1)\n",
        "            else:\n",
        "                RE = re.compile(r'^Masking_LSTM\\d+?_Densa\\d+?_DO.+' +\n",
        "                                column +\n",
        "                                '$')\n",
        "                # with tpu_strategy.scope():\n",
        "                model = crear_masking_lstm_densa_do(u_0,\n",
        "                                                    pasado_historico,\n",
        "                                                    horizonte_prevision,\n",
        "                                                    dropout=0.1,\n",
        "                                                    n_artributos=1)\n",
        "            # Nombre de modelo\n",
        "            nombre_modelo = '{}_batch{}-{}'.format(\n",
        "                model.name, batch_size,\n",
        "                column)\n",
        "            print(\"\\n\\n{}: Modelo \\t{}\".format(datetime.datetime.now(),\n",
        "                                               nombre_modelo))\n",
        "            # Ruta al modelo\n",
        "            path_modelo = os.path.join(modelo_mercado_path,\n",
        "                                       nombre_modelo + \".h5\")\n",
        "            if os.path.isfile(path_modelo):\n",
        "                # Cargar modelo\n",
        "                print(\"\\n{}: Cargando modelo:\\t{}\".format(\n",
        "                    datetime.datetime.now(), path_modelo))\n",
        "                model = keras.models.load_model(path_modelo)\n",
        "            else:\n",
        "                # Entrenar modelo\n",
        "                history = fit_model(x_train, y_train, batch_size)\n",
        "                \n",
        "                # Tiempo de entrenamiento\n",
        "                tiempo_entrenamiento()\n",
        "\n",
        "                # Guardar modelo\n",
        "                print(\"\\n{}: Guardando modelo:\\t{}\".format(\n",
        "                    datetime.datetime.now(), path_modelo))\n",
        "                model.save(path_modelo)\n",
        "                \n",
        "                # Plot history\n",
        "                plot_history(history)\n",
        "\n",
        "            # Info del modelo\n",
        "            print(\"\\n{}: Configuración del modelo:\".format(datetime.datetime.now()))\n",
        "            pprint.pprint(model.get_config())\n",
        "\n",
        "            # Pronóstico\n",
        "            fc = forecast_nn()\n",
        "\n",
        "            # Plot pronóstico\n",
        "            plot_pronos(df_test, nombre_modelo, column)\n",
        "\n",
        "            # Métricas\n",
        "            metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "\n",
        "            gc.collect()\n",
        "    plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-1X_VPcIVZQ"
      },
      "source": [
        "### 10- LSTM LSTM Densa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO4KeCktIVZQ"
      },
      "source": [
        "dir_modelo = \"10-LSTM_LSTM_Densa\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    \n",
        "    dataset = scaler.fit_transform(df[[column]])\n",
        "    test = dataset[-horizonte_prevision:]\n",
        "    train = dataset[:-horizonte_prevision]\n",
        "    x_train, y_train, x_test, y_test = datos_supervisados(\n",
        "        train, test, pasado_historico)\n",
        "    df_test = df[[column]].iloc[-horizonte_prevision:].copy()\n",
        "    for u_1 in tqdm_notebook([32, 64]):\n",
        "        for u_2 in tqdm_notebook([32, 64]):\n",
        "            for batch_size in tqdm_notebook([128]):\n",
        "                tiempo_inicio_fit = datetime.datetime.now()\n",
        "                match = re.search(\"[3-7]\", column)\n",
        "                if not match:\n",
        "                    RE = re.compile(\n",
        "                        r'^LSTM\\d+?_LSTM\\d+?_Densa\\d+?.+' +\n",
        "                        column + '$')\n",
        "                    # with tpu_strategy.scope():\n",
        "                    model = crear_lstm_lstm_densa(u_1,\n",
        "                                                  u_2,\n",
        "                                                  pasado_historico,\n",
        "                                                  horizonte_prevision,\n",
        "                                                  n_artributos=1)\n",
        "                else:\n",
        "                    RE = re.compile(\n",
        "                        r'^Masking_LSTM\\d+?_LSTM\\d+?_Densa\\d+?.+' +\n",
        "                        column + '$')\n",
        "                    # with tpu_strategy.scope():\n",
        "                    model = crear_masking_lstm_lstm_densa(u_1,\n",
        "                                                          u_2,\n",
        "                                                          pasado_historico,\n",
        "                                                          horizonte_prevision,\n",
        "                                                          n_artributos=1)\n",
        "                # Nombre de modelo\n",
        "                nombre_modelo = '{}_batch{}-{}'.format(\n",
        "                    model.name, batch_size,\n",
        "                    column)\n",
        "                print(\"\\n\\n{}: Modelo \\t{}\".format(datetime.datetime.now(),\n",
        "                                                   nombre_modelo))\n",
        "                # Ruta al modelo\n",
        "                path_modelo = os.path.join(modelo_mercado_path,\n",
        "                                           nombre_modelo + \".h5\")\n",
        "                if os.path.isfile(path_modelo):\n",
        "                    # Cargar modelo\n",
        "                    print(\"\\n{}: Cargando modelo:\\t{}\".format(\n",
        "                        datetime.datetime.now(), path_modelo))\n",
        "                    model = keras.models.load_model(path_modelo)\n",
        "                else:\n",
        "                    # Entrenar modelo\n",
        "                    history = fit_model(x_train, y_train, batch_size)\n",
        "                    \n",
        "                    # Tiempo de entrenamiento\n",
        "                    tiempo_entrenamiento()\n",
        "\n",
        "                    # Guardar modelo\n",
        "                    print(\"\\n{}: Guardando modelo:\\t{}\".format(\n",
        "                        datetime.datetime.now(), path_modelo))\n",
        "                    model.save(path_modelo)\n",
        "                    \n",
        "                    # Plot history\n",
        "                    plot_history(history)\n",
        "\n",
        "                # Info del modelo\n",
        "                print(\"\\n{}: Configuración del modelo:\".format(datetime.datetime.now()))\n",
        "                pprint.pprint(model.get_config())\n",
        "\n",
        "                # Pronóstico\n",
        "                fc = forecast_nn()\n",
        "\n",
        "                # Plot pronóstico\n",
        "                plot_pronos(df_test, nombre_modelo, column)\n",
        "\n",
        "                # Métricas\n",
        "                metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "                gc.collect()\n",
        "    plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U58jyFoUNc71"
      },
      "source": [
        "### 11- LSTM LSTM Densa DO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJHmQXfvBhUG"
      },
      "source": [
        "dir_modelo = \"11-LSTM_LSTM_Densa_DO\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    \n",
        "    dataset = scaler.fit_transform(df[[column]])\n",
        "    test = dataset[-horizonte_prevision:]\n",
        "    train = dataset[:-horizonte_prevision]\n",
        "    x_train, y_train, x_test, y_test = datos_supervisados(\n",
        "        train, test, pasado_historico)\n",
        "    df_test = df[[column]].iloc[-horizonte_prevision:].copy()\n",
        "    for u_1 in tqdm_notebook([32, 64]):\n",
        "        for u_2 in tqdm_notebook([32, 64]):\n",
        "            for batch_size in tqdm_notebook([128]):\n",
        "                tiempo_inicio_fit = datetime.datetime.now()\n",
        "                match = re.search(\"[3-7]\", column)\n",
        "                if not match:\n",
        "                    RE = re.compile(\n",
        "                        r'^LSTM\\d+?_LSTM\\d+?_Densa\\d+?_DO.+' +\n",
        "                        column + '$')\n",
        "                    # with tpu_strategy.scope():\n",
        "                    model = crear_lstm_lstm_densa_do(u_1,\n",
        "                                                     u_2,\n",
        "                                                     pasado_historico,\n",
        "                                                     horizonte_prevision,\n",
        "                                                     dropout=0.1,\n",
        "                                                     n_artributos=1)\n",
        "                else:\n",
        "                    RE = re.compile(\n",
        "                        r'^Masking_LSTM\\d+?_LSTM\\d+?_Densa\\d+?_DO.+' +\n",
        "                        column + '$')\n",
        "                    # with tpu_strategy.scope():\n",
        "                    model = crear_masking_lstm_lstm_densa_do(\n",
        "                        u_1,\n",
        "                        u_2,\n",
        "                        pasado_historico,\n",
        "                        horizonte_prevision,\n",
        "                        dropout=0.1,\n",
        "                        n_artributos=1)\n",
        "                # Nombre de modelo\n",
        "                nombre_modelo = '{}_batch{}-{}'.format(\n",
        "                    model.name, batch_size,\n",
        "                    column)\n",
        "                print(\"\\n\\n{}: Modelo \\t{}\".format(datetime.datetime.now(),\n",
        "                                                   nombre_modelo))\n",
        "                # Ruta al modelo\n",
        "                path_modelo = os.path.join(modelo_mercado_path,\n",
        "                                           nombre_modelo + \".h5\")\n",
        "                if os.path.isfile(path_modelo):\n",
        "                    # Cargar modelo\n",
        "                    print(\"\\n{}: Cargando modelo:\\t{}\".format(\n",
        "                        datetime.datetime.now(), path_modelo))\n",
        "                    model = keras.models.load_model(path_modelo)\n",
        "                else:\n",
        "                    # Entrenar modelo\n",
        "                    history = fit_model(x_train, y_train, batch_size)\n",
        "                    \n",
        "                    # Tiempo de entrenamiento\n",
        "                    tiempo_entrenamiento()\n",
        "\n",
        "                    # Guardar modelo\n",
        "                    print(\"\\n{}: Guardando modelo:\\t{}\".format(\n",
        "                        datetime.datetime.now(), path_modelo))\n",
        "                    model.save(path_modelo)\n",
        "                    \n",
        "                    # Plot history\n",
        "                    plot_history(history)\n",
        "\n",
        "                # Info del modelo               \n",
        "                print(\"\\n{}: Configuración del modelo:\".format(datetime.datetime.now()))\n",
        "                pprint.pprint(model.get_config())\n",
        "\n",
        "                # Pronóstico\n",
        "                fc = forecast_nn()\n",
        "\n",
        "                # Plot pronóstico\n",
        "                plot_pronos(df_test, nombre_modelo, column)\n",
        "\n",
        "                # Métricas\n",
        "                metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "                gc.collect()\n",
        "    plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdklEkWm4ZZQ"
      },
      "source": [
        "### 12- LSTM LSTM Densa Densa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXgVr3z64Znt"
      },
      "source": [
        "dir_modelo = \"12-LSTM_LSTM_Densa_Densa\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    \n",
        "    dataset = scaler.fit_transform(df[[column]])\n",
        "    test = dataset[-horizonte_prevision:]\n",
        "    train = dataset[:-horizonte_prevision]\n",
        "    x_train, y_train, x_test, y_test = datos_supervisados(\n",
        "        train, test, pasado_historico)\n",
        "    df_test = df[[column]].iloc[-horizonte_prevision:].copy()\n",
        "    for u_1 in tqdm_notebook([32, 64]):\n",
        "        for u_2 in tqdm_notebook([32, 64]):\n",
        "            for batch_size in tqdm_notebook([128]):\n",
        "                tiempo_inicio_fit = datetime.datetime.now()\n",
        "                match = re.search(\"[3-7]\", column)\n",
        "                if not match:\n",
        "                    RE = re.compile(\n",
        "                        r'^LSTM\\d+?_LSTM\\d+?_Densa\\d+?_Densa\\d+?.+' +\n",
        "                        column + '$')\n",
        "                    # with tpu_strategy.scope():\n",
        "                    model = crear_lstm_lstm_densa_densa(u_1,\n",
        "                                                        u_2,\n",
        "                                                        pasado_historico,\n",
        "                                                        horizonte_prevision,\n",
        "                                                        n_artributos=1)\n",
        "                else:\n",
        "                    RE = re.compile(\n",
        "                        r'^Masking_LSTM\\d+?_LSTM\\d+?_Densa\\d+?_Densa\\d+?.+' +\n",
        "                        column + '$')\n",
        "                    # with tpu_strategy.scope():\n",
        "                    model = crear_masking_lstm_lstm_densa_densa(\n",
        "                        u_1,\n",
        "                        u_2,\n",
        "                        pasado_historico,\n",
        "                        horizonte_prevision,\n",
        "                        n_artributos=1)\n",
        "                # Nombre de modelo\n",
        "                nombre_modelo = '{}_batch{}-{}'.format(\n",
        "                    model.name, batch_size,\n",
        "                    column)\n",
        "                print(\"\\n\\n{}: Modelo \\t{}\".format(datetime.datetime.now(),\n",
        "                                                   nombre_modelo))\n",
        "                # Ruta al modelo\n",
        "                path_modelo = os.path.join(modelo_mercado_path,\n",
        "                                           nombre_modelo + \".h5\")\n",
        "                if os.path.isfile(path_modelo):\n",
        "                    # Cargar modelo\n",
        "                    print(\"\\n{}: Cargando modelo:\\t{}\".format(\n",
        "                        datetime.datetime.now(), path_modelo))\n",
        "                    model = keras.models.load_model(path_modelo)\n",
        "                else:\n",
        "                    # Entrenar modelo\n",
        "                    history = fit_model(x_train, y_train, batch_size)\n",
        "                    \n",
        "                    # Tiempo de entrenamiento\n",
        "                    tiempo_entrenamiento()\n",
        "\n",
        "                    # Guardar modelo\n",
        "                    print(\"\\n{}: Guardando modelo:\\t{}\".format(\n",
        "                        datetime.datetime.now(), path_modelo))\n",
        "                    model.save(path_modelo)\n",
        "                    \n",
        "                    # Plot history\n",
        "                    plot_history(history)\n",
        "\n",
        "                # Info del modelo               \n",
        "                print(\"\\n{}: Configuración del modelo:\".format(datetime.datetime.now()))\n",
        "                pprint.pprint(model.get_config())\n",
        "\n",
        "                # Pronóstico\n",
        "                fc = forecast_nn()\n",
        "\n",
        "                # Plot pronóstico\n",
        "                plot_pronos(df_test, nombre_modelo, column)\n",
        "\n",
        "                # Métricas\n",
        "                metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "                gc.collect()\n",
        "    plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SONOLw1NdAq"
      },
      "source": [
        "### 13- LSTM LSTM Densa Densa DO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5d7Gzm4ExRc"
      },
      "source": [
        "dir_modelo = \"13-LSTM_LSTM_Densa_Densa_DO\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    \n",
        "    dataset = scaler.fit_transform(df[[column]])\n",
        "    test = dataset[-horizonte_prevision:]\n",
        "    train = dataset[:-horizonte_prevision]\n",
        "    x_train, y_train, x_test, y_test = datos_supervisados(\n",
        "        train, test, pasado_historico)\n",
        "    df_test = df[[column]].iloc[-horizonte_prevision:].copy()\n",
        "    for u_1 in tqdm_notebook([32, 64]):\n",
        "        for u_2 in tqdm_notebook([32, 64]):\n",
        "            for batch_size in tqdm_notebook([128]):\n",
        "                tiempo_inicio_fit = datetime.datetime.now()\n",
        "                match = re.search(\"[3-7]\", column)\n",
        "                if not match:\n",
        "                    RE = re.compile(\n",
        "                        r'^LSTM\\d+?_LSTM\\d+?_Densa\\d+?_Densa\\d+?_DO.+' +\n",
        "                        column + '$')\n",
        "                    # with tpu_strategy.scope():\n",
        "                    model = crear_lstm_lstm_densa_densa_do(u_1,\n",
        "                                                           u_2,\n",
        "                                                           pasado_historico,\n",
        "                                                           horizonte_prevision,\n",
        "                                                           dropout=0.1,\n",
        "                                                           n_artributos=1)\n",
        "                else:\n",
        "                    RE = re.compile(\n",
        "                        r'^Masking_LSTM\\d+?_LSTM\\d+?_Densa\\d+?_Densa\\d+?_DO.+'\n",
        "                        + column + '$')\n",
        "                    # with tpu_strategy.scope():\n",
        "                    model = crear_masking_lstm_lstm_densa_densa_do(\n",
        "                        u_1,\n",
        "                        u_2,\n",
        "                        pasado_historico,\n",
        "                        horizonte_prevision,\n",
        "                        dropout=0.1,\n",
        "                        n_artributos=1)\n",
        "                # Nombre de modelo\n",
        "                nombre_modelo = '{}_batch{}-{}'.format(\n",
        "                    model.name, batch_size,\n",
        "                    column)\n",
        "                print(\"\\n\\n{}: Modelo \\t{}\".format(datetime.datetime.now(),\n",
        "                                                   nombre_modelo))\n",
        "                # Ruta al modelo\n",
        "                path_modelo = os.path.join(modelo_mercado_path,\n",
        "                                           nombre_modelo + \".h5\")\n",
        "                if os.path.isfile(path_modelo):\n",
        "                    # Cargar modelo\n",
        "                    print(\"\\n{}: Cargando modelo:\\t{}\".format(\n",
        "                        datetime.datetime.now(), path_modelo))\n",
        "                    model = keras.models.load_model(path_modelo)\n",
        "                else:\n",
        "                    # Entrenar modelo\n",
        "                    history = fit_model(x_train, y_train, batch_size)\n",
        "                    \n",
        "                    # Tiempo de entrenamiento\n",
        "                    tiempo_entrenamiento()\n",
        "\n",
        "                    # Guardar modelo\n",
        "                    print(\"\\n{}: Guardando modelo:\\t{}\".format(\n",
        "                        datetime.datetime.now(), path_modelo))\n",
        "                    model.save(path_modelo)\n",
        "                    \n",
        "                    # Plot history\n",
        "                    plot_history(history)\n",
        "\n",
        "                # Info del modelo              \n",
        "                print(\"\\n{}: Configuración del modelo:\".format(datetime.datetime.now()))\n",
        "                pprint.pprint(model.get_config())\n",
        "\n",
        "                # Pronóstico\n",
        "                fc = forecast_nn()\n",
        "\n",
        "                # Plot pronóstico\n",
        "                plot_pronos(df_test, nombre_modelo, column)\n",
        "\n",
        "                # Métricas\n",
        "                metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "                gc.collect()\n",
        "    plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Upz-o4S2Ho76"
      },
      "source": [
        "### 14- LSTM LSTM LSTM Densa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdNYrS6VHo77"
      },
      "source": [
        "dir_modelo = \"14-LSTM_LSTM_LSTM_Densa\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    \n",
        "    dataset = scaler.fit_transform(df[[column]])\n",
        "    test = dataset[-horizonte_prevision:]\n",
        "    train = dataset[:-horizonte_prevision]\n",
        "    x_train, y_train, x_test, y_test = datos_supervisados(\n",
        "        train, test, pasado_historico)\n",
        "    df_test = df[[column]].iloc[-horizonte_prevision:].copy()\n",
        "    for u_1 in tqdm_notebook([32, 64]):\n",
        "        for u_2 in tqdm_notebook([32, 64]):\n",
        "            for u_3 in tqdm_notebook([32, 64]):\n",
        "                for batch_size in tqdm_notebook([128]):\n",
        "                    tiempo_inicio_fit = datetime.datetime.now()\n",
        "                    match = re.search(\"[3-7]\", column)\n",
        "                    if not match:\n",
        "                        RE = re.compile(\n",
        "                            r'^LSTM\\d+?_LSTM\\d+?_LSTM\\d+?_Densa\\d+?.+' +\n",
        "                            column + '$')\n",
        "                        # with tpu_strategy.scope():\n",
        "                        model = crear_lstm_lstm_lstm_densa(u_1,\n",
        "                                                           u_2,\n",
        "                                                           u_3,\n",
        "                                                           pasado_historico,\n",
        "                                                           horizonte_prevision,\n",
        "                                                           n_artributos=1)\n",
        "                    else:\n",
        "                        RE = re.compile(\n",
        "                            r'^Masking_LSTM\\d+?_LSTM\\d+?_LSTM\\d+?_Densa\\d+?.+'\n",
        "                            + column + '$')\n",
        "                        # with tpu_strategy.scope():\n",
        "                        model = crear_masking_lstm_lstm_lstm_densa(\n",
        "                            u_1,\n",
        "                            u_2,\n",
        "                            u_3,\n",
        "                            pasado_historico,\n",
        "                            horizonte_prevision,\n",
        "                            n_artributos=1)\n",
        "                    # Nombre de modelo\n",
        "                    nombre_modelo = '{}_batch{}-{}'.format(\n",
        "                        model.name, batch_size,\n",
        "                        column)\n",
        "                    print(\"\\n\\n{}: Modelo \\t{}\".format(datetime.datetime.now(),\n",
        "                                                       nombre_modelo))\n",
        "                    # Ruta al modelo\n",
        "                    path_modelo = os.path.join(modelo_mercado_path,\n",
        "                                               nombre_modelo + \".h5\")\n",
        "                    if os.path.isfile(path_modelo):\n",
        "                        # Cargar modelo\n",
        "                        print(\"\\n{}: Cargando modelo:\\t{}\".format(\n",
        "                            datetime.datetime.now(), path_modelo))\n",
        "                        model = keras.models.load_model(path_modelo)\n",
        "                    else:\n",
        "                        # Entrenar modelo\n",
        "                        history = fit_model(x_train, y_train, batch_size)\n",
        "                        \n",
        "                        # Tiempo de entrenamiento\n",
        "                        tiempo_entrenamiento()\n",
        "\n",
        "                        # Guardar modelo\n",
        "                        print(\"\\n{}: Guardando modelo:\\t{}\".format(\n",
        "                            datetime.datetime.now(), path_modelo))\n",
        "                        model.save(path_modelo)\n",
        "                        \n",
        "                        # Plot history\n",
        "                        plot_history(history)\n",
        "\n",
        "                    # Info del modelo                   \n",
        "                    print(\"\\n{}: Configuración del modelo:\".format(datetime.datetime.now()))\n",
        "                    pprint.pprint(model.get_config())\n",
        "\n",
        "                    # Pronóstico\n",
        "                    fc = forecast_nn()\n",
        "\n",
        "                    # Plot pronóstico\n",
        "                    plot_pronos(df_test, nombre_modelo, column)\n",
        "\n",
        "                    # Métricas\n",
        "                    metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "                    gc.collect()\n",
        "    plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47qEXJ7FCc5k"
      },
      "source": [
        "### 15- LSTM LSTM LSTM Densa DO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLqnsUGtCc5l"
      },
      "source": [
        "dir_modelo = \"15-LSTM_LSTM_LSTM_Densa_DO\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    \n",
        "    dataset = scaler.fit_transform(df[[column]])\n",
        "    test = dataset[-horizonte_prevision:]\n",
        "    train = dataset[:-horizonte_prevision]\n",
        "    x_train, y_train, x_test, y_test = datos_supervisados(\n",
        "        train, test, pasado_historico)\n",
        "    df_test = df[[column]].iloc[-horizonte_prevision:].copy()\n",
        "    for u_1 in tqdm_notebook([32, 64]):\n",
        "        for u_2 in tqdm_notebook([32, 64]):\n",
        "            for u_3 in tqdm_notebook([32, 64]):\n",
        "                for batch_size in tqdm_notebook([128]):\n",
        "                    tiempo_inicio_fit = datetime.datetime.now()\n",
        "                    match = re.search(\"[3-7]\", column)\n",
        "                    if not match:\n",
        "                        RE = re.compile(\n",
        "                            r'^LSTM\\d+?_LSTM\\d+?_LSTM\\d+?_Densa\\d+?_DO.+' +\n",
        "                            column + '$')\n",
        "                        # with tpu_strategy.scope():\n",
        "                        model = crear_lstm_lstm_lstm_densa_do(\n",
        "                            u_1,\n",
        "                            u_2,\n",
        "                            u_3,\n",
        "                            pasado_historico,\n",
        "                            horizonte_prevision,\n",
        "                            dropout=0.1,\n",
        "                            n_artributos=1)\n",
        "                    else:\n",
        "                        RE = re.compile(\n",
        "                            r'^Masking_LSTM\\d+?_LSTM\\d+?_LSTM\\d+?_Densa\\d+?_DO.+'\n",
        "                            + column + '$')\n",
        "                        # with tpu_strategy.scope():\n",
        "                        model = crear_masking_lstm_lstm_lstm_densa_do(\n",
        "                            u_1,\n",
        "                            u_2,\n",
        "                            u_3,\n",
        "                            pasado_historico,\n",
        "                            horizonte_prevision,\n",
        "                            dropout=0.1,\n",
        "                            n_artributos=1)\n",
        "                    # Nombre de modelo\n",
        "                    nombre_modelo = '{}_batch{}-{}'.format(\n",
        "                        model.name, batch_size,\n",
        "                        column)\n",
        "                    print(\"\\n\\n{}: Modelo \\t{}\".format(datetime.datetime.now(),\n",
        "                                                       nombre_modelo))\n",
        "                    # Ruta al modelo\n",
        "                    path_modelo = os.path.join(modelo_mercado_path,\n",
        "                                               nombre_modelo + \".h5\")\n",
        "                    if os.path.isfile(path_modelo):\n",
        "                        # Cargar modelo\n",
        "                        print(\"\\n{}: Cargando modelo:\\t{}\".format(\n",
        "                            datetime.datetime.now(), path_modelo))\n",
        "                        model = keras.models.load_model(path_modelo)\n",
        "                    else:\n",
        "                        # Entrenar modelo\n",
        "                        history = fit_model(x_train, y_train, batch_size)\n",
        "                        \n",
        "                        # Tiempo de entrenamiento\n",
        "                        tiempo_entrenamiento()\n",
        "\n",
        "                        # Guardar modelo\n",
        "                        print(\"\\n{}: Guardando modelo:\\t{}\".format(\n",
        "                            datetime.datetime.now(), path_modelo))\n",
        "                        model.save(path_modelo)\n",
        "                        \n",
        "                        # Plot history\n",
        "                        plot_history(history)\n",
        "\n",
        "                    # Info del modelo                    \n",
        "                    print(\"\\n{}: Configuración del modelo:\".format(datetime.datetime.now()))\n",
        "                    pprint.pprint(model.get_config())\n",
        "\n",
        "                    # Pronóstico\n",
        "                    fc = forecast_nn()\n",
        "\n",
        "                    # Plot pronóstico\n",
        "                    plot_pronos(df_test, nombre_modelo, column)\n",
        "\n",
        "                    # Métricas\n",
        "                    metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "                    gc.collect()\n",
        "    plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0rptD8yp7QM"
      },
      "source": [
        "## Gated recurrent unit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpznGBhXG5pq"
      },
      "source": [
        "### 16- GRU Flatten Densa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuB0ch9xB80s"
      },
      "source": [
        "dir_modelo = \"16-GRU_Flatten_Densa\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    \n",
        "    dataset = scaler.fit_transform(df[[column]])\n",
        "    test = dataset[-horizonte_prevision:]\n",
        "    train = dataset[:-horizonte_prevision]\n",
        "    x_train, y_train, x_test, y_test = datos_supervisados(\n",
        "        train, test, pasado_historico)\n",
        "    df_test = df[[column]].iloc[-horizonte_prevision:].copy()\n",
        "    for u_0 in tqdm_notebook([32, 64]):\n",
        "        for batch_size in tqdm_notebook([128]):\n",
        "            tiempo_inicio_fit = datetime.datetime.now()\n",
        "            match = re.search(\"[3-7]\", column)\n",
        "            if not match:\n",
        "                RE = re.compile(r'^GRU\\d+?_Flatten_Densa\\d+?.+' +\n",
        "                                column +\n",
        "                                '$')\n",
        "                # with tpu_strategy.scope():\n",
        "                model = crear_gru_flatten_densa(u_0,\n",
        "                                                pasado_historico,\n",
        "                                                horizonte_prevision,\n",
        "                                                n_artributos=1)\n",
        "            else:\n",
        "                RE = re.compile(r'^Masking_GRU\\d+?_Flatten_Densa\\d+?.+' +\n",
        "                                column +\n",
        "                                '$')\n",
        "                # with tpu_strategy.scope():\n",
        "                model = crear_masking_gru_flatten_densa(u_0,\n",
        "                                                        pasado_historico,\n",
        "                                                        horizonte_prevision,\n",
        "                                                        n_artributos=1)\n",
        "            # Nombre de modelo\n",
        "            nombre_modelo = '{}_batch{}-{}'.format(\n",
        "                model.name, batch_size,\n",
        "                column)\n",
        "            print(\"\\n\\n{}: Modelo \\t{}\".format(datetime.datetime.now(),\n",
        "                                               nombre_modelo))\n",
        "            # Ruta al modelo\n",
        "            path_modelo = os.path.join(modelo_mercado_path,\n",
        "                                       nombre_modelo + \".h5\")\n",
        "            if os.path.isfile(path_modelo):\n",
        "                # Cargar modelo\n",
        "                print(\"\\n{}: Cargando modelo:\\t{}\".format(\n",
        "                    datetime.datetime.now(), path_modelo))\n",
        "                model = keras.models.load_model(path_modelo)\n",
        "            else:\n",
        "                # Entrenar modelo\n",
        "                history = fit_model(x_train, y_train, batch_size)\n",
        "                \n",
        "                # Tiempo de entrenamiento\n",
        "                tiempo_entrenamiento()\n",
        "\n",
        "                # Guardar modelo\n",
        "                print(\"\\n{}: Guardando modelo:\\t{}\".format(\n",
        "                    datetime.datetime.now(), path_modelo))\n",
        "                model.save(path_modelo)\n",
        "                \n",
        "                # Plot history\n",
        "                plot_history(history)\n",
        "\n",
        "            # Info del modelo            \n",
        "            print(\"\\n{}: Configuración del modelo:\".format(datetime.datetime.now()))\n",
        "            pprint.pprint(model.get_config())\n",
        "\n",
        "            # Pronóstico\n",
        "            fc = forecast_nn()\n",
        "\n",
        "            # Plot pronóstico\n",
        "            plot_pronos(df_test, nombre_modelo, column)\n",
        "\n",
        "            # Métricas\n",
        "            metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "            gc.collect()\n",
        "    plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LB8Uy4UMFqp"
      },
      "source": [
        "### 17- GRU DO Flatten Densa "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7Yr-yJjMFqq"
      },
      "source": [
        "dir_modelo = \"17-GRU_DO_Flatten_Densa\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    \n",
        "    dataset = scaler.fit_transform(df[[column]])\n",
        "    test = dataset[-horizonte_prevision:]\n",
        "    train = dataset[:-horizonte_prevision]\n",
        "    x_train, y_train, x_test, y_test = datos_supervisados(\n",
        "        train, test, pasado_historico)\n",
        "    df_test = df[[column]].iloc[-horizonte_prevision:].copy()\n",
        "    for u_0 in tqdm_notebook([32, 64]):\n",
        "        for batch_size in tqdm_notebook([128]):\n",
        "            tiempo_inicio_fit = datetime.datetime.now()\n",
        "            match = re.search(\"[3-7]\", column)\n",
        "            if not match:\n",
        "                RE = re.compile(r'^GRU\\d+?_DO\\d+?_Flatten_Densa\\d+?.+' +\n",
        "                                column +\n",
        "                                '$')\n",
        "                # with tpu_strategy.scope():\n",
        "                model = crear_gru_do_flatten_densa(u_0,\n",
        "                                                   pasado_historico,\n",
        "                                                   horizonte_prevision,\n",
        "                                                   dropout=0.1,\n",
        "                                                   n_artributos=1)\n",
        "            else:\n",
        "                RE = re.compile(\n",
        "                    r'^Masking_GRU\\d+?_DO\\d+?_Flatten_Densa\\d+?.+' +\n",
        "                    column + '$')\n",
        "                # with tpu_strategy.scope():\n",
        "                model = crear_masking_gru_flatten_densa_do(u_0,\n",
        "                                                           pasado_historico,\n",
        "                                                           horizonte_prevision,\n",
        "                                                           dropout=0.1,\n",
        "                                                           n_artributos=1)\n",
        "            # Nombre de modelo\n",
        "            nombre_modelo = '{}_batch{}-{}'.format(\n",
        "                model.name, batch_size,\n",
        "                column)\n",
        "            print(\"\\n\\n{}: Modelo \\t{}\".format(datetime.datetime.now(),\n",
        "                                               nombre_modelo))\n",
        "            # Ruta al modelo\n",
        "            path_modelo = os.path.join(modelo_mercado_path,\n",
        "                                       nombre_modelo + \".h5\")\n",
        "            if os.path.isfile(path_modelo):\n",
        "                # Cargar modelo\n",
        "                print(\"\\n{}: Cargando modelo:\\t{}\".format(\n",
        "                    datetime.datetime.now(), path_modelo))\n",
        "                model = keras.models.load_model(path_modelo)\n",
        "                print(\"\\n{}: Sumario: \".format(datetime.datetime.now()))\n",
        "                pprint.pprint(model.summary())\n",
        "            else:\n",
        "                # Entrenar modelo\n",
        "                history = fit_model(x_train, y_train, batch_size)\n",
        "                \n",
        "                # Tiempo de entrenamiento\n",
        "                tiempo_entrenamiento()\n",
        "\n",
        "                # Guardar modelo\n",
        "                print(\"\\n{}: Guardando modelo:\\t{}\".format(\n",
        "                    datetime.datetime.now(), path_modelo))\n",
        "                model.save(path_modelo)\n",
        "                \n",
        "                # Plot history\n",
        "                plot_history(history)\n",
        "\n",
        "            # Info del modelo            \n",
        "            print(\"\\n{}: Configuración del modelo:\".format(datetime.datetime.now()))\n",
        "            pprint.pprint(model.get_config())\n",
        "\n",
        "            # Pronóstico\n",
        "            fc = forecast_nn()\n",
        "\n",
        "            # Plot pronóstico\n",
        "            plot_pronos(df_test, nombre_modelo, column)\n",
        "\n",
        "            # Métricas\n",
        "            metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "            gc.collect()\n",
        "    plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtLoH3lMGXiD"
      },
      "source": [
        "### 18- GRU GRU Flatten Densa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cDVbvi7GXiE"
      },
      "source": [
        "dir_modelo = \"18-GRU_GRU_Flatten_Densa\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "    # Directorios de modelo y mercado/s\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    # datos de entrenamiento y testeo\n",
        "    \n",
        "    dataset = scaler.fit_transform(df[[column]])\n",
        "    test = dataset[-horizonte_prevision:]\n",
        "    train = dataset[:-horizonte_prevision]\n",
        "    x_train, y_train, x_test, y_test = datos_supervisados(\n",
        "        train, test, pasado_historico)\n",
        "    df_test = df[[column]].iloc[-horizonte_prevision:].copy()\n",
        "    for u_1 in tqdm_notebook([32, 64]):\n",
        "        for u_2 in tqdm_notebook([32, 64]):\n",
        "            for batch_size in tqdm_notebook([128]):\n",
        "                tiempo_inicio_fit = datetime.datetime.now()\n",
        "                match = re.search(\"[3-7]\", column)\n",
        "                if not match:\n",
        "                    RE = re.compile(\n",
        "                        r'^GRU\\d+?_GRU\\d+?_Flatten_Densa\\d+?.+' +\n",
        "                        column + '$')\n",
        "                    # with tpu_strategy.scope():\n",
        "                    model = crear_gru_gru_flatten_densa(u_1,\n",
        "                                                        u_2,\n",
        "                                                        pasado_historico,\n",
        "                                                        horizonte_prevision,\n",
        "                                                        n_artributos=1)\n",
        "                else:\n",
        "                    RE = re.compile(\n",
        "                        r'^Masking_GRU\\d+?_GRU\\d+?_Flatten_Densa\\d+?.+' +\n",
        "                        column + '$')\n",
        "                    # with tpu_strategy.scope():\n",
        "                    model = crear_masking_gru_gru_flatten_densa(\n",
        "                        u_1,\n",
        "                        u_2,\n",
        "                        pasado_historico,\n",
        "                        horizonte_prevision,\n",
        "                        n_artributos=1)\n",
        "                # Nombre de modelo\n",
        "                nombre_modelo = '{}_batch{}-{}'.format(\n",
        "                    model.name, batch_size,\n",
        "                    column)\n",
        "                print(\"\\n\\n{}: Modelo \\t{}\".format(datetime.datetime.now(),\n",
        "                                                   nombre_modelo))\n",
        "                # Ruta al modelo\n",
        "                path_modelo = os.path.join(modelo_mercado_path,\n",
        "                                           nombre_modelo + \".h5\")\n",
        "                if os.path.isfile(path_modelo):\n",
        "                    # Cargar modelo\n",
        "                    print(\"\\n{}: Cargando modelo:\\t{}\".format(\n",
        "                        datetime.datetime.now(), path_modelo))\n",
        "                    model = keras.models.load_model(path_modelo)\n",
        "                else:\n",
        "                    # Entrenar modelo\n",
        "                    history = fit_model(x_train, y_train, batch_size)\n",
        "                    \n",
        "                    # Tiempo de entrenamiento\n",
        "                    tiempo_entrenamiento()\n",
        "\n",
        "                    # Guardar modelo\n",
        "                    print(\"\\n{}: Guardando modelo:\\t{}\".format(\n",
        "                        datetime.datetime.now(), path_modelo))\n",
        "                    model.save(path_modelo)\n",
        "                    \n",
        "                    # Plot history\n",
        "                    plot_history(history)\n",
        "\n",
        "                # Info del modelo                \n",
        "                print(\"\\n{}: Configuración del modelo:\".format(datetime.datetime.now()))\n",
        "                pprint.pprint(model.get_config())\n",
        "\n",
        "                # Pronóstico\n",
        "                fc = forecast_nn()\n",
        "\n",
        "                # Plot pronóstico\n",
        "                plot_pronos(df_test, nombre_modelo, column)\n",
        "\n",
        "                # Métricas\n",
        "                metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "                gc.collect()\n",
        "    plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrfFkFfD8T9W"
      },
      "source": [
        "### 19- GRU DO GRU DO Flatten Densa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeGbgG5v8T9Y"
      },
      "source": [
        "dir_modelo = \"19-GRU_DO_GRU_DO_Flatten_Densa\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "\n",
        "    # Directorios de modelo y mercado/s\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    # datos de entrenamiento y testeo\n",
        "    \n",
        "    dataset = scaler.fit_transform(df[[column]])\n",
        "    test = dataset[-horizonte_prevision:]\n",
        "    train = dataset[:-horizonte_prevision]\n",
        "    x_train, y_train, x_test, y_test = datos_supervisados(\n",
        "        train, test, pasado_historico)\n",
        "    df_test = df[[column]].iloc[-horizonte_prevision:].copy()\n",
        "    for u_1 in tqdm_notebook([32, 64]):\n",
        "        for u_2 in tqdm_notebook([32, 64]):\n",
        "            for batch_size in tqdm_notebook([128]):\n",
        "                tiempo_inicio_fit = datetime.datetime.now()\n",
        "                match = re.search(\"[3-7]\", column)\n",
        "                if not match:\n",
        "                    RE = re.compile(\n",
        "                        r'^GRU\\d+?_DO\\d+?_GRU\\d+?_DO\\d+?_Flatten_Densa\\d+?.+' +\n",
        "                        column + '$')\n",
        "                    # with tpu_strategy.scope():\n",
        "                    model = crear_gru_do_gru_do_flatten_densa(\n",
        "                        u_1,\n",
        "                        u_2,\n",
        "                        pasado_historico,\n",
        "                        horizonte_prevision,\n",
        "                        dropout=0.1,\n",
        "                        n_artributos=1)\n",
        "                else:\n",
        "                    RE = re.compile(\n",
        "                        r'^Masking_GRU\\d+?_DO\\d+?_GRU\\d+?_DO\\d+?_Flatten_Densa\\d+?.+'\n",
        "                        + column + '$')\n",
        "                    # with tpu_strategy.scope():\n",
        "                    model = crear_masking_gru_do_gru_do_flatten_densa(\n",
        "                        u_1,\n",
        "                        u_2,\n",
        "                        pasado_historico,\n",
        "                        horizonte_prevision,\n",
        "                        dropout=0.1,\n",
        "                        n_artributos=1)\n",
        "                # Nombre de modelo\n",
        "                nombre_modelo = '{}_batch{}-{}'.format(\n",
        "                    model.name, batch_size,\n",
        "                    column)\n",
        "                print(\"\\n\\n{}: Modelo \\t{}\".format(datetime.datetime.now(),\n",
        "                                                   nombre_modelo))\n",
        "                # Ruta al modelo\n",
        "                path_modelo = os.path.join(modelo_mercado_path,\n",
        "                                           nombre_modelo + \".h5\")\n",
        "                if os.path.isfile(path_modelo):\n",
        "                    # Cargar modelo\n",
        "                    print(\"\\n{}: Cargando modelo:\\t{}\".format(\n",
        "                        datetime.datetime.now(), path_modelo))\n",
        "                    model = keras.models.load_model(path_modelo)\n",
        "                else:\n",
        "                    # Entrenar modelo\n",
        "                    history = fit_model(x_train, y_train, batch_size)\n",
        "                    \n",
        "                    # Tiempo de entrenamiento\n",
        "                    tiempo_entrenamiento()\n",
        "\n",
        "                    # Guardar modelo\n",
        "                    print(\"\\n{}: Guardando modelo:\\t{}\".format(\n",
        "                        datetime.datetime.now(), path_modelo))\n",
        "                    model.save(path_modelo)\n",
        "                    \n",
        "                    # Plot history\n",
        "                    plot_history(history)\n",
        "\n",
        "                # Info del modelo                \n",
        "                print(\"\\n{}: Configuración del modelo:\".format(datetime.datetime.now()))\n",
        "                pprint.pprint(model.get_config())\n",
        "\n",
        "                # Pronóstico\n",
        "                fc = forecast_nn()\n",
        "\n",
        "                # Plot pronóstico\n",
        "                plot_pronos(df_test, nombre_modelo, column)\n",
        "\n",
        "                # Métricas\n",
        "                metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "                gc.collect()\n",
        "    plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAQX9LDcFjQc"
      },
      "source": [
        "### 20- GRU GRU Flatten Densa Densa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIduWGhtFjQc"
      },
      "source": [
        "dir_modelo = \"20-GRU_GRU_Flatten_Densa_Densa\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "\n",
        "    # Regex para filtrar los resultados\n",
        "\n",
        "    # Directorios de modelo y mercado/s\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    # datos de entrenamiento y testeo\n",
        "    \n",
        "    dataset = scaler.fit_transform(df[[column]])\n",
        "    test = dataset[-horizonte_prevision:]\n",
        "    train = dataset[:-horizonte_prevision]\n",
        "    x_train, y_train, x_test, y_test = datos_supervisados(\n",
        "        train, test, pasado_historico)\n",
        "    df_test = df[[column]].iloc[-horizonte_prevision:].copy()\n",
        "    for u_1 in tqdm_notebook([32, 64]):\n",
        "        for u_2 in tqdm_notebook([32, 64]):\n",
        "            for batch_size in tqdm_notebook([128]):\n",
        "                tiempo_inicio_fit = datetime.datetime.now()\n",
        "                match = re.search(\"[3-7]\", column)\n",
        "                if not match:\n",
        "                    RE = re.compile(\n",
        "                        r'^GRU\\d+?_GRU\\d+?_Flatten_Densa\\d+?_Densa\\d+?.+' +\n",
        "                        column + '$')\n",
        "                    # with tpu_strategy.scope():\n",
        "                    model = crear_gru_gru_flatten_densa_densa(\n",
        "                        u_1,\n",
        "                        u_2,\n",
        "                        pasado_historico,\n",
        "                        horizonte_prevision,\n",
        "                        n_artributos=1)\n",
        "                else:\n",
        "                    RE = re.compile(\n",
        "                        r'^Masking_GRU\\d+?_GRU\\d+?_Flatten_Densa\\d+?_Densa\\d+?.+'\n",
        "                        + column + '$')\n",
        "                    # with tpu_strategy.scope():\n",
        "                    model = crear_masking_gru_gru_flatten_densa_densa(\n",
        "                        u_1,\n",
        "                        u_2,\n",
        "                        pasado_historico,\n",
        "                        horizonte_prevision,\n",
        "                        n_artributos=1)\n",
        "                # Nombre de modelo\n",
        "                nombre_modelo = '{}_batch{}-{}'.format(\n",
        "                    model.name, batch_size,\n",
        "                    column)\n",
        "                print(\"\\n\\n{}: Modelo \\t{}\".format(datetime.datetime.now(),\n",
        "                                                   nombre_modelo))\n",
        "                # Ruta al modelo\n",
        "                path_modelo = os.path.join(modelo_mercado_path,\n",
        "                                           nombre_modelo + \".h5\")\n",
        "                if os.path.isfile(path_modelo):\n",
        "                    # Cargar modelo\n",
        "                    print(\"\\n{}: Cargando modelo:\\t{}\".format(\n",
        "                        datetime.datetime.now(), path_modelo))\n",
        "                    model = keras.models.load_model(path_modelo)\n",
        "                else:\n",
        "                    # Entrenar modelo\n",
        "                    history = fit_model(x_train, y_train, batch_size)\n",
        "                    \n",
        "                    # Tiempo de entrenamiento\n",
        "                    tiempo_entrenamiento()\n",
        "\n",
        "                    # Guardar modelo\n",
        "                    print(\"\\n{}: Guardando modelo:\\t{}\".format(\n",
        "                        datetime.datetime.now(), path_modelo))\n",
        "                    model.save(path_modelo)\n",
        "                    \n",
        "                    # Plot history\n",
        "                    plot_history(history)\n",
        "\n",
        "                # Info del modelo                \n",
        "                print(\"\\n{}: Configuración del modelo:\".format(datetime.datetime.now()))\n",
        "                pprint.pprint(model.get_config())\n",
        "\n",
        "                # Pronóstico\n",
        "                fc = forecast_nn()\n",
        "\n",
        "                # Plot pronóstico\n",
        "                plot_pronos(df_test, nombre_modelo, column)\n",
        "\n",
        "                # Métricas\n",
        "                metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "                gc.collect()\n",
        "    plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEr60E_E07eo"
      },
      "source": [
        "### 21- GRU DO GRU DO Flatten Densa Densa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTnLSCum07ep"
      },
      "source": [
        "dir_modelo = \"21-GRU_DO_GRU_DO_Flatten_Densa_Densa\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "\n",
        "    # Directorios de modelo y mercado/s\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    # datos de entrenamiento y testeo\n",
        "    \n",
        "    dataset = scaler.fit_transform(df[[column]])\n",
        "    test = dataset[-horizonte_prevision:]\n",
        "    train = dataset[:-horizonte_prevision]\n",
        "    x_train, y_train, x_test, y_test = datos_supervisados(\n",
        "        train, test, pasado_historico)\n",
        "    df_test = df[[column]].iloc[-horizonte_prevision:].copy()\n",
        "    for u_1 in tqdm_notebook([32, 64]):\n",
        "        for u_2 in tqdm_notebook([32, 64]):\n",
        "            for batch_size in tqdm_notebook([128]):\n",
        "                tiempo_inicio_fit = datetime.datetime.now()\n",
        "                match = re.search(\"[3-7]\", column)\n",
        "                if not match:\n",
        "                    RE = re.compile(\n",
        "                        r'^GRU\\d+?_DO\\d+?_GRU\\d+?_DO\\d+?_Flatten_Densa\\d+?_Densa\\d+?.+'\n",
        "                        + column + '$')\n",
        "                    # with tpu_strategy.scope():\n",
        "                    model = crear_gru_do_gru_do_flatten_densa_densa(\n",
        "                        u_1,\n",
        "                        u_2,\n",
        "                        pasado_historico,\n",
        "                        horizonte_prevision,\n",
        "                        dropout=0.1,\n",
        "                        n_artributos=1)\n",
        "                else:\n",
        "                    RE = re.compile(\n",
        "                        r'^Masking_GRU\\d+?_DO\\d+?_GRU\\d+?_DO\\d+?_Flatten_Densa\\d+?_Densa\\d+?.+'\n",
        "                        + column + '$')\n",
        "                    # with tpu_strategy.scope():\n",
        "                    model = crear_masking_gru_do_gru_do_flatten_densa_densa(\n",
        "                        u_1,\n",
        "                        u_2,\n",
        "                        pasado_historico,\n",
        "                        horizonte_prevision,\n",
        "                        dropout=0.1,\n",
        "                        n_artributos=1)\n",
        "                # Nombre de modelo\n",
        "                nombre_modelo = '{}_batch{}-{}'.format(\n",
        "                    model.name, batch_size,\n",
        "                    column)\n",
        "                print(\"\\n\\n{}: Modelo \\t{}\".format(datetime.datetime.now(),\n",
        "                                                   nombre_modelo))\n",
        "                # Ruta al modelo\n",
        "                path_modelo = os.path.join(modelo_mercado_path,\n",
        "                                           nombre_modelo + \".h5\")\n",
        "                if os.path.isfile(path_modelo):\n",
        "                    # Cargar modelo\n",
        "                    print(\"\\n{}: Cargando modelo:\\t{}\".format(\n",
        "                        datetime.datetime.now(), path_modelo))\n",
        "                    model = keras.models.load_model(path_modelo)\n",
        "                else:\n",
        "                    # Entrenar modelo\n",
        "                    history = fit_model(x_train, y_train, batch_size)\n",
        "                    \n",
        "                    # Tiempo de entrenamiento\n",
        "                    tiempo_entrenamiento()\n",
        "\n",
        "                    # Guardar modelo\n",
        "                    print(\"\\n{}: Guardando modelo:\\t{}\".format(\n",
        "                        datetime.datetime.now(), path_modelo))\n",
        "                    model.save(path_modelo)\n",
        "                    \n",
        "                    # Plot history\n",
        "                    plot_history(history)\n",
        "\n",
        "                # Info del modelo                \n",
        "                print(\"\\n{}: Configuración del modelo:\".format(datetime.datetime.now()))\n",
        "                pprint.pprint(model.get_config())\n",
        "\n",
        "                # Pronóstico\n",
        "                fc = forecast_nn()\n",
        "\n",
        "                # Plot pronóstico\n",
        "                plot_pronos(df_test, nombre_modelo, column)\n",
        "\n",
        "                # Métricas\n",
        "                metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "                gc.collect()\n",
        "    plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfhu_rLo8T9s"
      },
      "source": [
        "### 22- GRU GRU GRU Flatten Densa  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiKKC0T8WJgg"
      },
      "source": [
        "dir_modelo = \"22-GRU_GRU_GRU_Flatten_Densa\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "    # Regex para filtrar los resultados\n",
        "\n",
        "    # Directorios de modelo y mercado/s\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    # datos de entrenamiento y testeo\n",
        "    \n",
        "    dataset = scaler.fit_transform(df[[column]])\n",
        "    test = dataset[-horizonte_prevision:]\n",
        "    train = dataset[:-horizonte_prevision]\n",
        "    x_train, y_train, x_test, y_test = datos_supervisados(\n",
        "        train, test, pasado_historico)\n",
        "    df_test = df[[column]].iloc[-horizonte_prevision:].copy()\n",
        "    for u_1 in tqdm_notebook([32, 64]):\n",
        "        for u_2 in tqdm_notebook([32, 64]):\n",
        "            for u_3 in tqdm_notebook([32, 64]):\n",
        "                for batch_size in tqdm_notebook([128]):\n",
        "                    tiempo_inicio_fit = datetime.datetime.now()\n",
        "                    match = re.search(\"[3-7]\", column)\n",
        "                    if not match:\n",
        "                        RE = re.compile(\n",
        "                            r'^GRU\\d+?_GRU\\d+?_GRU\\d+?_Flatten_Densa\\d+?.+' +\n",
        "                            column + '$')\n",
        "                        # with tpu_strategy.scope():\n",
        "                        model = crear_gru_gru_gru_flatten_densa(\n",
        "                            u_1,\n",
        "                            u_2,\n",
        "                            u_3,\n",
        "                            pasado_historico,\n",
        "                            horizonte_prevision,\n",
        "                            n_artributos=1)\n",
        "                    else:\n",
        "                        RE = re.compile(\n",
        "                            r'^Masking_GRU\\d+?_GRU\\d+?_GRU\\d+?_Flatten_Densa\\d+?.+'\n",
        "                            + column + '$')\n",
        "                        # with tpu_strategy.scope():\n",
        "                        model = crear_masking_gru_gru_gru_flatten_densa(\n",
        "                            u_1,\n",
        "                            u_2,\n",
        "                            u_3,\n",
        "                            pasado_historico,\n",
        "                            horizonte_prevision,\n",
        "                            n_artributos=1)\n",
        "                    # Nombre de modelo\n",
        "                    nombre_modelo = '{}_batch{}-{}'.format(\n",
        "                        model.name, batch_size,\n",
        "                        column)\n",
        "                    print(\"\\n\\n{}: Modelo \\t{}\".format(datetime.datetime.now(),\n",
        "                                                       nombre_modelo))\n",
        "                    # Ruta al modelo\n",
        "                    path_modelo = os.path.join(modelo_mercado_path,\n",
        "                                               nombre_modelo + \".h5\")\n",
        "                    if os.path.isfile(path_modelo):\n",
        "                        # Cargar modelo\n",
        "                        print(\"\\n{}: Cargando modelo:\\t{}\".format(\n",
        "                            datetime.datetime.now(), path_modelo))\n",
        "                        model = keras.models.load_model(path_modelo)\n",
        "                    else:\n",
        "                        # Entrenar modelo\n",
        "                        history = fit_model(x_train, y_train, batch_size)\n",
        "                        \n",
        "                        # Tiempo de entrenamiento\n",
        "                        tiempo_entrenamiento()\n",
        "\n",
        "                        # Guardar modelo\n",
        "                        print(\"\\n{}: Guardando modelo:\\t{}\".format(\n",
        "                            datetime.datetime.now(), path_modelo))\n",
        "                        model.save(path_modelo)\n",
        "                        \n",
        "                        # Plot history\n",
        "                        plot_history(history)\n",
        "\n",
        "                    # Info del modelo                    \n",
        "                    print(\"\\n{}: Configuración del modelo:\".format(datetime.datetime.now()))\n",
        "                    pprint.pprint(model.get_config())\n",
        "\n",
        "                    # Pronóstico\n",
        "                    fc = forecast_nn()\n",
        "\n",
        "                    # Plot pronóstico\n",
        "                    plot_pronos(df_test, nombre_modelo, column)\n",
        "\n",
        "                    # Métricas\n",
        "                    metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "                    gc.collect()\n",
        "    plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjEcRuw-2mSZ"
      },
      "source": [
        "### 23- GRU DO GRU DO GRU DO Flatten Densa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B-qO7FR2mSZ"
      },
      "source": [
        "dir_modelo = \"23-GRU_DO_GRU_DO_GRU_DO_Flatten_Densa\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "\n",
        "    # Directorios de modelo y mercado/s\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    # datos de entrenamiento y testeo\n",
        "    \n",
        "    dataset = scaler.fit_transform(df[[column]])\n",
        "    test = dataset[-horizonte_prevision:]\n",
        "    train = dataset[:-horizonte_prevision]\n",
        "    x_train, y_train, x_test, y_test = datos_supervisados(\n",
        "        train, test, pasado_historico)\n",
        "    df_test = df[[column]].iloc[-horizonte_prevision:].copy()\n",
        "    for u_1 in tqdm_notebook([32, 64]):\n",
        "        for u_2 in tqdm_notebook([32, 64]):\n",
        "            for u_3 in tqdm_notebook([32, 64]):\n",
        "                for batch_size in tqdm_notebook([128]):\n",
        "                    tiempo_inicio_fit = datetime.datetime.now()\n",
        "                    match = re.search(\"[3-7]\", column)\n",
        "                    if not match:\n",
        "                        RE = re.compile(\n",
        "                            r'^GRU\\d+?_DO\\d+?_GRU\\d+?_DO\\d+?_GRU\\d+?_DO\\d+?_Flatten_Densa\\d+?.+'\n",
        "                            + column + '$')\n",
        "                        # with tpu_strategy.scope():\n",
        "                        model = crear_gru_do_gru_do_gru_do_flatten_densa(\n",
        "                            u_1,\n",
        "                            u_2,\n",
        "                            u_3,\n",
        "                            pasado_historico,\n",
        "                            horizonte_prevision,\n",
        "                            dropout=0.1,\n",
        "                            n_artributos=1)\n",
        "                    else:\n",
        "                        RE = re.compile(\n",
        "                            r'^Masking_GRU\\d+?_DO\\d+?_GRU\\d+?_DO\\d+?_GRU\\d+?_DO\\d+?_Flatten_Densa\\d+?.+'\n",
        "                            + column + '$')\n",
        "                        # with tpu_strategy.scope():\n",
        "                        model = crear_masking_gru_do_gru_do_gru_do_flatten_densa(\n",
        "                            u_1,\n",
        "                            u_2,\n",
        "                            u_3,\n",
        "                            pasado_historico,\n",
        "                            horizonte_prevision,\n",
        "                            dropout=0.1,\n",
        "                            n_artributos=1)\n",
        "                    # Nombre de modelo\n",
        "                    nombre_modelo = '{}_batch{}-{}'.format(\n",
        "                        model.name, batch_size,\n",
        "                        column)\n",
        "                    print(\"\\n\\n{}: Modelo \\t{}\".format(datetime.datetime.now(),\n",
        "                                                       nombre_modelo))\n",
        "                    # Ruta al modelo\n",
        "                    path_modelo = os.path.join(modelo_mercado_path,\n",
        "                                               nombre_modelo + \".h5\")\n",
        "                    if os.path.isfile(path_modelo):\n",
        "                        # Cargar modelo\n",
        "                        print(\"\\n{}: Cargando modelo:\\t{}\".format(\n",
        "                            datetime.datetime.now(), path_modelo))\n",
        "                        model = keras.models.load_model(path_modelo)\n",
        "                    else:\n",
        "                        # Entrenar modelo\n",
        "                        history = fit_model(x_train, y_train, batch_size)\n",
        "                        \n",
        "                        # Tiempo de entrenamiento\n",
        "                        tiempo_entrenamiento()\n",
        "\n",
        "                        # Guardar modelo\n",
        "                        print(\"\\n{}: Guardando modelo:\\t{}\".format(\n",
        "                            datetime.datetime.now(), path_modelo))\n",
        "                        model.save(path_modelo)\n",
        "                        \n",
        "                        # Plot history\n",
        "                        plot_history(history)\n",
        "\n",
        "                    # Info del modelo                    \n",
        "                    print(\"\\n{}: Configuración del modelo:\".format(datetime.datetime.now()))\n",
        "                    pprint.pprint(model.get_config())\n",
        "\n",
        "                    # Pronóstico\n",
        "                    fc = forecast_nn()\n",
        "\n",
        "                    # Plot pronóstico\n",
        "                    plot_pronos(df_test, nombre_modelo, column)\n",
        "\n",
        "                    # Métricas\n",
        "                    metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "                    gc.collect()\n",
        "    plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZooX0vb2K-J"
      },
      "source": [
        "# REDES NEURONALES CONVOLUCIONALES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0m5KocVqPS4"
      },
      "source": [
        "## Convolutional Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69kucKT7-0D5"
      },
      "source": [
        "### 24- Conv1D MaxPool1D Flatten Densa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3XJbA_F-0D6"
      },
      "source": [
        "dir_modelo = \"24-Conv1D_MaxPool1D_Flatten_Densa\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "    # Directorios de modelo y mercado/s\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    # datos de entrenamiento y testeo\n",
        "    \n",
        "    dataset = scaler.fit_transform(df[[column]])\n",
        "    test = dataset[-horizonte_prevision:]\n",
        "    train = dataset[:-horizonte_prevision]\n",
        "    x_train, y_train, x_test, y_test = datos_supervisados(\n",
        "        train, test, pasado_historico)\n",
        "    df_test = df[[column]].iloc[-horizonte_prevision:].copy()\n",
        "    for u_0 in tqdm_notebook([32, 64]):\n",
        "        for batch_size in tqdm_notebook([128]):\n",
        "            tiempo_inicio_fit = datetime.datetime.now()\n",
        "            match = re.search(\"[3-7]\", column)\n",
        "            if not match:\n",
        "                RE = re.compile(r'^Conv1D\\d+?_MaxPool1D2_Flatten_Densa\\d+?.+' +\n",
        "                                column +\n",
        "                                '$')\n",
        "                # with tpu_strategy.scope():\n",
        "                model = crear_conv1d_maxpool1d_flatten_densa(\n",
        "                    u_0,\n",
        "                    pasado_historico,\n",
        "                    horizonte_prevision,\n",
        "                    n_artributos=1)\n",
        "            else:\n",
        "                RE = re.compile(\n",
        "                    r'^Masking_Conv1D\\d+?_MaxPool1D2_Flatten_Densa\\d+?.+' +\n",
        "                    column + '$')\n",
        "                # with tpu_strategy.scope():\n",
        "                model = crear_masking_conv1d_maxpool1d_flatten_densa(\n",
        "                    u_1,\n",
        "                    pasado_historico,\n",
        "                    horizonte_prevision,\n",
        "                    n_artributos=1)\n",
        "            # Nombre de modelo\n",
        "            nombre_modelo = '{}_batch{}-{}'.format(\n",
        "                model.name, batch_size,\n",
        "                column)\n",
        "            print(\"\\n\\n{}: Modelo \\t{}\".format(datetime.datetime.now(),\n",
        "                                               nombre_modelo))\n",
        "            # Ruta al modelo\n",
        "            path_modelo = os.path.join(modelo_mercado_path,\n",
        "                                       nombre_modelo + \".h5\")\n",
        "            if os.path.isfile(path_modelo):\n",
        "                # Cargar modelo\n",
        "                print(\"\\n{}: Cargando modelo:\\t{}\".format(\n",
        "                    datetime.datetime.now(), path_modelo))\n",
        "                model = keras.models.load_model(path_modelo)\n",
        "            else:\n",
        "                # Entrenar modelo\n",
        "                history = fit_model(x_train, y_train, batch_size)\n",
        "                \n",
        "                # Tiempo de entrenamiento\n",
        "                tiempo_entrenamiento()\n",
        "\n",
        "                # Guardar modelo\n",
        "                print(\"\\n{}: Guardando modelo:\\t{}\".format(\n",
        "                    datetime.datetime.now(), path_modelo))\n",
        "                model.save(path_modelo)\n",
        "                \n",
        "                # Plot history\n",
        "                plot_history(history)\n",
        "\n",
        "            # Info del modelo            \n",
        "            print(\"\\n{}: Configuración del modelo:\".format(datetime.datetime.now()))\n",
        "            pprint.pprint(model.get_config())\n",
        "\n",
        "            # Pronóstico\n",
        "            fc = forecast_nn()\n",
        "\n",
        "            # Plot pronóstico\n",
        "            plot_pronos(df_test, nombre_modelo, column)\n",
        "\n",
        "            # Métricas\n",
        "            metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "            gc.collect()\n",
        "    plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ7VRNkH-0D7"
      },
      "source": [
        "### 25- Conv1D DO MaxPool1D Flatten Densa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MrC5737-0D7"
      },
      "source": [
        "dir_modelo = \"25-Conv1D_do_MaxPool1D_Flatten_Densa\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "    # Directorios de modelo y mercado/s\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    # datos de entrenamiento y testeo\n",
        "    \n",
        "    dataset = scaler.fit_transform(df[[column]])\n",
        "    test = dataset[-horizonte_prevision:]\n",
        "    train = dataset[:-horizonte_prevision]\n",
        "    x_train, y_train, x_test, y_test = datos_supervisados(\n",
        "        train, test, pasado_historico)\n",
        "    df_test = df[[column]].iloc[-horizonte_prevision:].copy()\n",
        "    for u_0 in tqdm_notebook([32, 64]):\n",
        "        for batch_size in tqdm_notebook([128]):\n",
        "            tiempo_inicio_fit = datetime.datetime.now()\n",
        "            match = re.search(\"[3-7]\", column)\n",
        "            if not match:\n",
        "                RE = re.compile(\n",
        "                    r'^Conv1D\\d+?_DO\\d+?_MaxPool1D2_Flatten_Densa\\d+?.+' +\n",
        "                    column + '$')\n",
        "                # with tpu_strategy.scope():\n",
        "                model = crear_conv1d_do_maxpool1d_flatten_densa(\n",
        "                    u_0,\n",
        "                    pasado_historico,\n",
        "                    horizonte_prevision,\n",
        "                    dropout=0.1,\n",
        "                    n_artributos=1)\n",
        "            else:\n",
        "                RE = re.compile(\n",
        "                    r'^Masking_Conv1D\\d+?_DO\\d+?_MaxPool1D2_Flatten_Densa\\d+?.+'\n",
        "                    + column + '$')\n",
        "                # with tpu_strategy.scope():\n",
        "                model = crear_masking_conv1d_do_maxpool1d_flatten_densa(\n",
        "                    u_1,\n",
        "                    pasado_historico,\n",
        "                    horizonte_prevision,\n",
        "                    dropout=0.1,\n",
        "                    n_artributos=1)\n",
        "            # Nombre de modelo\n",
        "            nombre_modelo = '{}_batch{}-{}'.format(\n",
        "                model.name, batch_size,\n",
        "                column)\n",
        "            print(\"\\n\\n{}: Modelo \\t{}\".format(datetime.datetime.now(),\n",
        "                                               nombre_modelo))\n",
        "            # Ruta al modelo\n",
        "            path_modelo = os.path.join(modelo_mercado_path,\n",
        "                                       nombre_modelo + \".h5\")\n",
        "            if os.path.isfile(path_modelo):\n",
        "                # Cargar modelo\n",
        "                print(\"\\n{}: Cargando modelo:\\t{}\".format(\n",
        "                    datetime.datetime.now(), path_modelo))\n",
        "                model = keras.models.load_model(path_modelo)\n",
        "            else:\n",
        "                # Entrenar modelo\n",
        "                history = fit_model(x_train, y_train, batch_size)\n",
        "                \n",
        "                # Tiempo de entrenamiento\n",
        "                tiempo_entrenamiento()\n",
        "\n",
        "                # Guardar modelo\n",
        "                print(\"\\n{}: Guardando modelo:\\t{}\".format(\n",
        "                    datetime.datetime.now(), path_modelo))\n",
        "                model.save(path_modelo)\n",
        "                \n",
        "                # Plot history\n",
        "                plot_history(history)\n",
        "\n",
        "            # Info del modelo            \n",
        "            print(\"\\n{}: Configuración del modelo:\".format(datetime.datetime.now()))\n",
        "            pprint.pprint(model.get_config())\n",
        "\n",
        "            # Pronóstico\n",
        "            fc = forecast_nn()\n",
        "\n",
        "            # Plot pronóstico\n",
        "            plot_pronos(df_test, nombre_modelo, column)\n",
        "\n",
        "            # Métricas\n",
        "            metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "            gc.collect()\n",
        "    plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EUrXlGj4M1h"
      },
      "source": [
        "### 26- Conv1D MaxPool1D Conv1D MaxPool1D Flatten Densa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bL1WVtR4Rum"
      },
      "source": [
        "dir_modelo = \"26-Conv1D_MaxPool1D_Conv1D_MaxPool1D_Flatten_Densa\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "    # Directorios de modelo y mercado/s\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    # datos de entrenamiento y testeo\n",
        "    \n",
        "    dataset = scaler.fit_transform(df[[column]])\n",
        "    test = dataset[-horizonte_prevision:]\n",
        "    train = dataset[:-horizonte_prevision]\n",
        "    x_train, y_train, x_test, y_test = datos_supervisados(\n",
        "        train, test, pasado_historico)\n",
        "    df_test = df[[column]].iloc[-horizonte_prevision:].copy()\n",
        "    for u_1 in tqdm_notebook([32, 64]):\n",
        "        for u_2 in tqdm_notebook([32, 64]):\n",
        "            for batch_size in tqdm_notebook([128]):\n",
        "                tiempo_inicio_fit = datetime.datetime.now()\n",
        "                match = re.search(\"[3-7]\", column)\n",
        "                if not match:\n",
        "                    RE = re.compile(\n",
        "                        r'^Conv1D\\d+?_MaxPool1D2_Conv1D\\d+?_MaxPool1D2_Flatten_Densa\\d+?.+'\n",
        "                        + column + '$')\n",
        "                    # with tpu_strategy.scope():\n",
        "                    model = crear_conv1d_maxpool1d_conv1d_maxpool1d_flatten_densa(\n",
        "                        u_1,\n",
        "                        u_2,\n",
        "                        pasado_historico,\n",
        "                        horizonte_prevision,\n",
        "                        n_artributos=1)\n",
        "                else:\n",
        "                    RE = re.compile(\n",
        "                        r'^Masking_Conv1D\\d+?_MaxPool1D2_Conv1D\\d+?_MaxPool1D2_Flatten_Densa\\d+?.+'\n",
        "                        + column + '$')\n",
        "                    # with tpu_strategy.scope():\n",
        "                    model = crear_masking_conv1d_maxpool1d_conv1d_maxpool1d_flatten_densa(\n",
        "                        u_1,\n",
        "                        u_2,\n",
        "                        pasado_historico,\n",
        "                        horizonte_prevision,\n",
        "                        n_artributos=1)\n",
        "                # Nombre de modelo\n",
        "                nombre_modelo = '{}_batch{}-{}'.format(\n",
        "                    model.name, batch_size,\n",
        "                    column)\n",
        "                print(\"\\n\\n{}: Modelo \\t{}\".format(datetime.datetime.now(),\n",
        "                                                   nombre_modelo))\n",
        "                # Ruta al modelo\n",
        "                path_modelo = os.path.join(modelo_mercado_path,\n",
        "                                           nombre_modelo + \".h5\")\n",
        "                if os.path.isfile(path_modelo):\n",
        "                    # Cargar modelo\n",
        "                    print(\"\\n{}: Cargando modelo:\\t{}\".format(\n",
        "                        datetime.datetime.now(), path_modelo))\n",
        "                    model = keras.models.load_model(path_modelo)\n",
        "                else:\n",
        "                    # Entrenar modelo\n",
        "                    history = fit_model(x_train, y_train, batch_size)\n",
        "                    \n",
        "                    # Tiempo de entrenamiento\n",
        "                    tiempo_entrenamiento()\n",
        "\n",
        "                    # Guardar modelo\n",
        "                    print(\"\\n{}: Guardando modelo:\\t{}\".format(\n",
        "                        datetime.datetime.now(), path_modelo))\n",
        "                    model.save(path_modelo)\n",
        "                    \n",
        "                    # Plot history\n",
        "                    plot_history(history)\n",
        "\n",
        "                # Info del modelo                \n",
        "                print(\"\\n{}: Configuración del modelo:\".format(datetime.datetime.now()))\n",
        "                pprint.pprint(model.get_config())\n",
        "\n",
        "                # Pronóstico\n",
        "                fc = forecast_nn()\n",
        "\n",
        "                # Plot pronóstico\n",
        "                plot_pronos(df_test, nombre_modelo, column)\n",
        "\n",
        "                # Métricas\n",
        "                metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "                gc.collect()\n",
        "    plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RB5VBTxGTdg"
      },
      "source": [
        "\n",
        "### 27- Conv1D DO MaxPool1D Conv1D DO MaxPool1D Flatten Densa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNQWdBviXOuX"
      },
      "source": [
        "dir_modelo = \"27-Conv1D_DO_MaxPool1D_Conv1D_DO_MaxPool1D_Flatten_Densa\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "    # Directorios de modelo y mercado/s\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    # datos de entrenamiento y testeo\n",
        "    \n",
        "    dataset = scaler.fit_transform(df[[column]])\n",
        "    test = dataset[-horizonte_prevision:]\n",
        "    train = dataset[:-horizonte_prevision]\n",
        "    x_train, y_train, x_test, y_test = datos_supervisados(\n",
        "        train, test, pasado_historico)\n",
        "    df_test = df[[column]].iloc[-horizonte_prevision:].copy()\n",
        "    for u_1 in tqdm_notebook([32, 64]):\n",
        "        for u_2 in tqdm_notebook([32, 64]):\n",
        "            for batch_size in tqdm_notebook([128]):\n",
        "                tiempo_inicio_fit = datetime.datetime.now()\n",
        "                match = re.search(\"[3-7]\", column)\n",
        "                if not match:\n",
        "                    RE = re.compile(\n",
        "                        r'^Conv1D\\d+?_DO\\d+?_MaxPool1D2_Conv1D\\d+?_DO\\d+?_MaxPool1D2_Flatten_Densa\\d+?.+'\n",
        "                        + column + '$')\n",
        "                    # with tpu_strategy.scope():\n",
        "                    model = crear_conv1d_do_maxpool1d_conv1d_do_maxpool1d_flatten_densa(\n",
        "                        u_1,\n",
        "                        u_2,\n",
        "                        pasado_historico,\n",
        "                        horizonte_prevision,\n",
        "                        dropout=0.1,\n",
        "                        n_artributos=1)\n",
        "                else:\n",
        "                    RE = re.compile(\n",
        "                        r'^Masking_Conv1D\\d+?_DO\\d+?_MaxPool1D2_Conv1D\\d+?_DO\\d+?_MaxPool1D2_Flatten_Densa\\d+?.+'\n",
        "                        + column + '$')\n",
        "                    # with tpu_strategy.scope():\n",
        "                    model = crear_masking_conv1d_do_maxpool1d_conv1d_do_maxpool1d_flatten_densa(\n",
        "                        u_1,\n",
        "                        u_2,\n",
        "                        pasado_historico,\n",
        "                        horizonte_prevision,\n",
        "                        dropout=0.1,\n",
        "                        n_artributos=1)\n",
        "                # Nombre de modelo\n",
        "                nombre_modelo = '{}_batch{}-{}'.format(\n",
        "                    model.name, batch_size,\n",
        "                    column)\n",
        "                print(\"\\n\\n{}: Modelo \\t{}\".format(datetime.datetime.now(),\n",
        "                                                   nombre_modelo))\n",
        "                # Ruta al modelo\n",
        "                path_modelo = os.path.join(modelo_mercado_path,\n",
        "                                           nombre_modelo + \".h5\")\n",
        "                if os.path.isfile(path_modelo):\n",
        "                    # Cargar modelo\n",
        "                    print(\"\\n{}: Cargando modelo:\\t{}\".format(\n",
        "                        datetime.datetime.now(), path_modelo))\n",
        "                    model = keras.models.load_model(path_modelo)\n",
        "                else:\n",
        "                    # Entrenar modelo\n",
        "                    history = fit_model(x_train, y_train, batch_size)\n",
        "                    \n",
        "                    # Tiempo de entrenamiento\n",
        "                    tiempo_entrenamiento()\n",
        "\n",
        "                    # Guardar modelo\n",
        "                    print(\"\\n{}: Guardando modelo:\\t{}\".format(\n",
        "                        datetime.datetime.now(), path_modelo))\n",
        "                    model.save(path_modelo)\n",
        "                    \n",
        "                    # Plot history\n",
        "                    plot_history(history)\n",
        "\n",
        "                # Info del modelo                \n",
        "                print(\"\\n{}: Configuración del modelo:\".format(datetime.datetime.now()))\n",
        "                pprint.pprint(model.get_config())\n",
        "\n",
        "                # Pronóstico\n",
        "                fc = forecast_nn()\n",
        "\n",
        "                # Plot pronóstico\n",
        "                plot_pronos(df_test, nombre_modelo, column)\n",
        "\n",
        "                # Métricas\n",
        "                metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "                gc.collect()\n",
        "    plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEFH8gmXqM4I"
      },
      "source": [
        "## Temporal Convolutional Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81FkRlhNfILR"
      },
      "source": [
        "### 28- TCN Densa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCoG3ug2XMVq"
      },
      "source": [
        "dir_modelo = \"28-TCN_Densa\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "\n",
        "    # Directorios de modelo y mercado/s\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    # datos de entrenamiento y testeo\n",
        "    \n",
        "    dataset = scaler.fit_transform(df[[column]])\n",
        "    test = dataset[-horizonte_prevision:]\n",
        "    train = dataset[:-horizonte_prevision]\n",
        "    x_train, y_train, x_test, y_test = datos_supervisados(\n",
        "        train, test, pasado_historico)\n",
        "    df_test = df[[column]].iloc[-horizonte_prevision:].copy()\n",
        "    for u_0 in tqdm_notebook([32, 64]):\n",
        "        for batch_size in tqdm_notebook([128]):\n",
        "            tiempo_inicio_fit = datetime.datetime.now()\n",
        "            match = re.search(\"[3-7]\", column)\n",
        "            if not match:\n",
        "                RE = re.compile(r'^TCN\\d+?_Densa\\d+?.+' +\n",
        "                                column +\n",
        "                                '$')\n",
        "                #with tpu_strategy.scope():\n",
        "                model = crear_TCN_densa(u_0,\n",
        "                                        pasado_historico,\n",
        "                                        horizonte_prevision,\n",
        "                                        n_artributos=1)\n",
        "            else:\n",
        "                RE = re.compile(r'^Masking_TCN\\d+?_Densa\\d+?.+' +\n",
        "                                column +\n",
        "                                '$')\n",
        "                #with tpu_strategy.scope():\n",
        "                model = crear_masking_TCN_densa(u_0,\n",
        "                                                pasado_historico,\n",
        "                                                horizonte_prevision,\n",
        "                                                n_artributos=1)\n",
        "            # Nombre de modelo\n",
        "            nombre_modelo = '{}_batch{}-{}'.format(\n",
        "                model.name, batch_size,\n",
        "                column)\n",
        "            print(\"\\n\\n{}: Modelo \\t{}\".format(datetime.datetime.now(),\n",
        "                                               nombre_modelo))\n",
        "            # Ruta al modelo\n",
        "            path_modelo = os.path.join(modelo_mercado_path,\n",
        "                                       nombre_modelo + \".tf\")\n",
        "            if os.path.isdir(path_modelo):\n",
        "                # Cargar modelo\n",
        "                print(\"\\n{}: Cargando modelo:\\t{}\".format(\n",
        "                    datetime.datetime.now(), path_modelo))\n",
        "                model = keras.models.load_model(path_modelo)\n",
        "            else:\n",
        "                # Entrenar modelo\n",
        "                history = fit_model(x_train, y_train, batch_size)\n",
        "                \n",
        "                # Tiempo de entrenamiento\n",
        "                tiempo_entrenamiento()\n",
        "\n",
        "                # Guardar modelo\n",
        "                print(\"\\n{}: Guardando modelo:\\t{}\".format(\n",
        "                    datetime.datetime.now(), path_modelo))\n",
        "                model.save(path_modelo)\n",
        "                \n",
        "                # Plot history\n",
        "                plot_history(history)\n",
        "\n",
        "            # Info del modelo            \n",
        "            print(\"\\n{}: Configuración del modelo:\".format(datetime.datetime.now()))\n",
        "            pprint.pprint(model.get_config())\n",
        "\n",
        "            # Pronóstico\n",
        "            fc = forecast_nn()\n",
        "\n",
        "            # Plot pronóstico\n",
        "            plot_pronos(df_test, nombre_modelo, column)\n",
        "\n",
        "            # Métricas\n",
        "            metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "            gc.collect()\n",
        "    plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynDMBq4ODM8z"
      },
      "source": [
        "### 29- TCN DO Densa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVw3T0lADM8z"
      },
      "source": [
        "dir_modelo = \"29-TCN_DO_Densa\"\n",
        "modelo_path, tabla_path, plot_path = mk_model_dirs(dir_modelo)\n",
        "for column in tqdm_notebook(df.columns):\n",
        "\n",
        "    # Directorios de modelo y mercado/s\n",
        "    modelo_mercado_path, tabla_mercado_path, plot_mercado_path = mk_model_mercado_dirs(\n",
        "        column)\n",
        "    # datos de entrenamiento y testeo\n",
        "    \n",
        "    dataset = scaler.fit_transform(df[[column]])\n",
        "    test = dataset[-horizonte_prevision:]\n",
        "    train = dataset[:-horizonte_prevision]\n",
        "    x_train, y_train, x_test, y_test = datos_supervisados(\n",
        "        train, test, pasado_historico)\n",
        "    df_test = df[[column]].iloc[-horizonte_prevision:].copy()\n",
        "    for u_0 in tqdm_notebook([32, 64]):\n",
        "        for batch_size in tqdm_notebook([128]):\n",
        "            tiempo_inicio_fit = datetime.datetime.now()\n",
        "            match = re.search(\"[3-7]\", column)\n",
        "            if not match:\n",
        "                RE = re.compile(r'^TCN\\d+?_DO\\d+?_Densa\\d+?.+' +\n",
        "                                column +\n",
        "                                '$')\n",
        "                # with tpu_strategy.scope():\n",
        "                model = crear_TCN_do_densa(u_0,\n",
        "                                           pasado_historico,\n",
        "                                           horizonte_prevision,\n",
        "                                           dropout=0.1,\n",
        "                                           n_artributos=1)\n",
        "            else:\n",
        "                RE = re.compile(r'^Masking_TCN\\d+?_DO\\d+?_Densa\\d+?.+' +\n",
        "                                column +\n",
        "                                '$')\n",
        "                # with tpu_strategy.scope():\n",
        "                model = crear_masking_TCN_do_densa(u_0,\n",
        "                                                   pasado_historico,\n",
        "                                                   horizonte_prevision,\n",
        "                                                   dropout=0.1,\n",
        "                                                   n_artributos=1)\n",
        "            # Nombre de modelo\n",
        "            nombre_modelo = '{}_batch{}-{}'.format(\n",
        "                model.name, batch_size,\n",
        "                column)\n",
        "            print(\"\\n\\n{}: Modelo \\t{}\".format(datetime.datetime.now(),\n",
        "                                               nombre_modelo))\n",
        "            # Ruta al modelo\n",
        "            path_modelo = os.path.join(modelo_mercado_path,\n",
        "                                       nombre_modelo + \".tf\")\n",
        "            if os.path.isdir(path_modelo):\n",
        "                # Cargar modelo\n",
        "                print(\"\\n{}: Cargando modelo:\\t{}\".format(\n",
        "                    datetime.datetime.now(), path_modelo))\n",
        "                model = keras.models.load_model(path_modelo)\n",
        "            else:\n",
        "                # Entrenar modelo\n",
        "                history = fit_model(x_train, y_train, batch_size)\n",
        "                \n",
        "                # Tiempo de entrenamiento\n",
        "                tiempo_entrenamiento()\n",
        "\n",
        "                # Guardar modelo\n",
        "                print(\"\\n{}: Guardando modelo:\\t{}\".format(\n",
        "                    datetime.datetime.now(), path_modelo))\n",
        "                model.save(path_modelo)\n",
        "                \n",
        "                # Plot history\n",
        "                plot_history(history)\n",
        "\n",
        "            # Info del modelo            \n",
        "            print(\"\\n{}: Configuración del modelo:\".format(datetime.datetime.now()))\n",
        "            pprint.pprint(model.get_config())\n",
        "\n",
        "            # Pronóstico\n",
        "            fc = forecast_nn()\n",
        "\n",
        "            # Plot pronóstico\n",
        "            plot_pronos(df_test, nombre_modelo, column)\n",
        "\n",
        "            # Métricas\n",
        "            metrics_time_series(df_test[column], fc, res_pronos, nombre_modelo)\n",
        "            gc.collect()\n",
        "\n",
        "    plot_metrics(pd.DataFrame(res_pronos), plot_mercado_path, RE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWEKEQ6-wJNn"
      },
      "source": [
        "# RESULTADOS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ETQJfNoi-I3"
      },
      "source": [
        "## Recolectar métricas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YJrGhfrBs3N"
      },
      "source": [
        "path_metr = os.path.join(sumario_path, \"00-metricas_sumario.csv\")\n",
        "if os.path.isfile(path_metr):\n",
        "    metricas_df = pd.read_csv(path_metr)\n",
        "    metricas_df.set_index('Modelo', inplace=True)\n",
        "else:\n",
        "    metricas_lst = glob.glob(tablas_path + '/*/*/*_m*.csv')\n",
        "    metrica_data = []\n",
        "    for filename in tqdm_notebook(metricas_lst):\n",
        "        data = pd.read_csv(filename)\n",
        "        metrica_data.append(data)\n",
        "    metricas_data_concat = pd.concat(metrica_data)\n",
        "    metricas_data_concat.rename(columns={\"Unnamed: 0\": \"Modelo\"}, inplace=True)\n",
        "    metricas_data_concat.replace(regex=r'-Precio_mercado_SPOT_',\n",
        "                                 value='-',\n",
        "                                 inplace=True)\n",
        "    metricas_data_concat.sort_values(\n",
        "        by=[\"R2\", \"EVS\", \"MAE\", \"MSE\", \"MAPE\", \"ME\"],\n",
        "        ascending=[False, False, True, True, True, True],\n",
        "        inplace=True)\n",
        "    metricas_data_concat.drop_duplicates(keep='first', inplace=True)\n",
        "    metricas_data_concat.set_index('Modelo', inplace=True)\n",
        "    metricas_df = metricas_data_concat[~metricas_data_concat.index.duplicated(\n",
        "        keep='first')]\n",
        "    metricas_df.to_csv(path_metr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Zu6asq6bqNG"
      },
      "source": [
        "## Mejor modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eXHTlI53L2j"
      },
      "source": [
        "for column in tqdm_notebook(df.columns):\n",
        "    RE = re.compile(r'.*?' + column + \"$\")\n",
        "    mejor_modelo = metricas_df.filter(regex=RE, axis=0).head(1)\n",
        "    mejor_modelo_path = os.path.join(\n",
        "        sumario_path, \"01-mejor_modelo-\" + column + \"-metricas_sumario.csv\")\n",
        "    if not mejor_modelo.empty:\n",
        "        mejor_modelo.to_csv(mejor_modelo_path)\n",
        "        print(mejor_modelo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jjv8pXPSbufi"
      },
      "source": [
        "## Coeficiente de determinación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XKTzT0_5TI5"
      },
      "source": [
        "metrica = \"R2\"\n",
        "for column in tqdm_notebook(df.columns):\n",
        "    re_AUTOARIMA = re.compile(r'^AUTOARIMA_100.+' +\n",
        "                              column + \"$\")\n",
        "    met = metricas_df.filter(regex=column,\n",
        "                             axis=0)\n",
        "    met_AUTOARIMA = met.filter(regex=re_AUTOARIMA, axis=0)\n",
        "    met = met.sort_values(by=[metrica], ascending=False).head(20)\n",
        "    met.sort_values(by=[\"R2\", \"EVS\", \"MAE\", \"MSE\", \"MAPE\", \"ME\"],\n",
        "                    ascending=[False, False, True, True, True, True],\n",
        "                    inplace=True)\n",
        "    met = met.head(20)\n",
        "    met = pd.concat([met, met_AUTOARIMA], axis=0)\n",
        "    path_met = os.path.join(\n",
        "        sumario_path, \"01-\" + metrica + \"-\" + column + \"-metricas_sumario.csv\")\n",
        "    print(path_met)\n",
        "    print(met)\n",
        "    met.to_csv(path_met)\n",
        "    met.sort_values(by=[metrica], ascending=True, inplace=True)\n",
        "    plt.rcParams['figure.figsize'] = (15, int(len(met) / 1.5))\n",
        "    met[metrica].plot(kind='barh',\n",
        "                      fontsize=20,\n",
        "                      color=tuple(np.where(met[metrica] < 0, 'r', 'b')))\n",
        "    for index, value in enumerate(met[metrica]):\n",
        "        plt.text(value,\n",
        "                 index,\n",
        "                 str(round(value, 3)),\n",
        "                 size=18,\n",
        "                 fontweight=\"bold\")\n",
        "    plt.title(column.replace(\"_\", \" \") + '\\nCoeficiente de determinación (R2)',\n",
        "              size=28)\n",
        "    plt.ylabel('Modelos', fontsize=26)\n",
        "    path_met_plot = os.path.join(\n",
        "        sumario_path, \"02-\" + metrica + \"-\" + column + \"-metricas_sumario.png\")\n",
        "    print(path_met_plot)\n",
        "    plt.savefig(path_met_plot, bbox_inches=\"tight\")\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGUsELw4Hmnb"
      },
      "source": [
        "## Recolectar pronósticos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLhJAcvhhx3o"
      },
      "source": [
        "path_prons = os.path.join(sumario_path, \"03-pronosticos_sumario.csv\")\n",
        "if os.path.isfile(path_prons):\n",
        "    pronos_df = pd.read_csv(path_prons)\n",
        "    pronos_df.set_index('Creado_el', inplace=True)\n",
        "else:\n",
        "    pronosticos_data = []\n",
        "    pronosticos_lst = glob.glob(tablas_path + '/*/*/*_p.csv')\n",
        "    for filename in tqdm_notebook(pronosticos_lst):\n",
        "        data = pd.read_csv(filename)\n",
        "        pronosticos_data.append(data)\n",
        "\n",
        "    pronos_data = []\n",
        "    for df_ in tqdm_notebook(pronosticos_data):\n",
        "        if len(df_) == 7:\n",
        "            df_ = df_.set_index('Creado_el')\n",
        "            pronos_data.append(df_)\n",
        "\n",
        "    pronos_df = pd.concat(pronos_data, axis=1)\n",
        "    pronos_df.drop_duplicates(inplace=True)\n",
        "    pronos_df = pronos_df.T.drop_duplicates().T\n",
        "    pronos_df = pronos_df.rename(\n",
        "        columns=lambda s: s.replace('-Precio_mercado_SPOT_', '-'))\n",
        "    pronos_df = pronos_df.loc[:, ~pronos_df.columns.duplicated()]\n",
        "    pronos_df.to_csv(path_prons)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oamFPFSyjEej"
      },
      "source": [
        "## Plot \"top\" por modelo y mercado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXFxAaOsge-1"
      },
      "source": [
        "top = 1  # top 1\n",
        "for column in tqdm_notebook(df.columns):\n",
        "    regexs = mk_regexs(column)\n",
        "    for reg in tqdm_notebook(regexs):\n",
        "        mejor_modelo = metricas_df.filter(regex=reg, axis=0).head(top)\n",
        "        if not mejor_modelo.empty:\n",
        "            print(mejor_modelo)\n",
        "            mejores_modelos = mejor_modelo.index.to_list()\n",
        "            mejores_modelos.insert(0, column)\n",
        "            pronos_df.filter(items=mejores_modelos).plot(figsize=(15, 7))\n",
        "            plt.ylabel('Ventas')\n",
        "            plt.xlabel('Tiempo')\n",
        "            plt.title(\"Mejor pronósticos para:\\n\" + column.replace(\"_\", \" \"),\n",
        "                      size=18)\n",
        "            plt.legend(loc=2)\n",
        "            path_mejor_plot = os.path.join(\n",
        "                sumario_path,\n",
        "                \"05-\" + column + \"-\" +\n",
        "                mejores_modelos[1] + \"-pronosticos_sumario.png\")\n",
        "            plt.grid(True)\n",
        "            plt.savefig(path_mejor_plot, bbox_inches=\"tight\")\n",
        "            plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}